{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0219d472",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#1) Import libraries\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import Environments\n",
    "from collections import OrderedDict\n",
    "from torch.distributions import MultivariateNormal, Categorical, Binomial\n",
    "from torch.nn import Softmax\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "# I use the work of Eric Yu to help me build this algorithm. Link: https://github.com/ericyangyu/PPO-for-Beginners\n",
    "#https://github.com/nikhilbarhate99/PPO-PyTorch/blob/master/PPO.py\n",
    "\n",
    "#2) Set up Neural Network functions and classes\n",
    "    \n",
    "class Model_PPO(nn.Module):\n",
    "    \"\"\"\n",
    "        Class: actor NN\n",
    "        :param np_inputs: size input of the NN (size state)\n",
    "        :param nb_outputs: size output of the NN (size action)\n",
    "    \"\"\"  \n",
    "    def __init__(self, np_inputs, nb_outputs, model_type=0, nb_car=1, mean=0, std=1):\n",
    "        super(Model_PPO, self).__init__()\n",
    "        self.model_type=model_type\n",
    "        self.nb_car=nb_car\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.layer1 = nn.Linear(np_inputs, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, nb_outputs)\n",
    "        if(self.model_type==2):\n",
    "            self.layer4 = nn.Linear(32, nb_outputs)\n",
    "            #self.layers_d = [nn.Linear(32, nb_outputs) for i in range(self.nb_car)]\n",
    "            self.return_layer=Softmax(dim=-1)\n",
    "        if(self.model_type==1):\n",
    "            self.layer4 = nn.Linear(32, nb_outputs)\n",
    "            self.return_layer=nn.Tanh()\n",
    "        else: #self.model_type==0\n",
    "            pass\n",
    "        #torch.nn.init.uniform_(self.layer4.weight,0.003, 0.006)\n",
    "        torch.nn.init.orthogonal_(self.layer4.weight)\n",
    "\n",
    "    def forward(self, input1):\n",
    "        \"\"\"\n",
    "        Forward NN : compute the NN with respect the current state\n",
    "        :param input1: state\n",
    "        :r(eturn: output of the NN, action\n",
    "        \"\"\" \n",
    "        if isinstance(input1, np.ndarray):\n",
    "            input1 = torch.tensor(input1, dtype=torch.float)\n",
    "        activation1 = F.relu(self.layer1(input1))\n",
    "        activation2 = F.relu(self.layer2(activation1))\n",
    "        activation3 = F.relu(self.layer3(activation2))\n",
    "        if(self.model_type==2):\n",
    "            output_d = self.layer4(activation3)\n",
    "            output_d=output_d.reshape(-1,2)\n",
    "            output_d=self.return_layer(output_d)\n",
    "            output=torch.flatten(output_d)\n",
    "\n",
    "        elif(self.model_type==1):\n",
    "            output = self.layer4(activation3)\n",
    "            output=torch.add(torch.mul(self.return_layer(output), self.std),self.mean)\n",
    "\n",
    "        else:#self.model_type==0\n",
    "            output = self.layer4(activation3)\n",
    "        return output\n",
    "#3) Rollout on the environment:\n",
    "from collections import deque\n",
    "class Env_rollout:\n",
    "    \"\"\" \n",
    "        Class : iterate on the environment\n",
    "        :param env: our environment\n",
    "        :param max_steps: max steps per episode\n",
    "    \"\"\"\n",
    "    def __init__(self, env, nb_cars, max_steps, dt):\n",
    "        self.env = env\n",
    "        self.nb_cars=nb_cars\n",
    "        self.dt=dt\n",
    "        self.max_steps = max_steps\n",
    "        self.prev_state, _ = env.reset()\n",
    "        self.shape_env=2+9+2\n",
    "        self.shape_env_d=2+(5*(nb_cars-1))+8+2\n",
    "        self.batch_obs_cross=[]\n",
    "        self.batch_obs_wait=[]\n",
    "        self.batch_acts_choice=[] # changer par shape(-1,2)\n",
    "        self.batch_acts_cross=[]\n",
    "        self.batch_acts_wait=[]\n",
    "        self.batch_log_probs_choice=[]\n",
    "        self.batch_log_probs_cross=[]\n",
    "        self.batch_log_probs_wait=[]\n",
    "        self.batch_rews_choice = []\n",
    "        self.batch_rews_cross = []\n",
    "        self.batch_rews_wait = []\n",
    "        self.return_softmax=Softmax(dim=-1)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset: reinitilization (lists et environment).\n",
    "        \"\"\"\n",
    "        self.prev_state, _ = env.reset()\n",
    "        self.batch_obs_choice=[]\n",
    "        self.batch_obs_cross=[]\n",
    "        self.batch_obs_wait=[]\n",
    "        self.batch_acts_choice=[]\n",
    "        self.batch_acts_cross=[]\n",
    "        self.batch_acts_wait=[]\n",
    "        self.batch_log_probs_choice=[]\n",
    "        self.batch_log_probs_cross=[]\n",
    "        self.batch_log_probs_wait=[]\n",
    "        self.batch_rews_choice = []\n",
    "        self.batch_rews_cross = []\n",
    "        self.batch_rews_wait = []\n",
    "    \n",
    "    def reward_choice(self, reward_light):\n",
    "        \"\"\"\n",
    "        Reward of the discrete NN\n",
    "        \"\"\"\n",
    "        return reward_light\n",
    "\n",
    "    def iterations(self, actor_net_cross, actor_net_wait, actor_net_choice, nbr_episodes,choix=False):\n",
    "        \"\"\"\n",
    "        Iterate on the environment.\n",
    "        :param actor_net: current policy (actor NN)\n",
    "        :param nbr_episodes: episode number\n",
    "        :return: Tensors; state batch, action batch\n",
    "        \"\"\"\n",
    "        batch_obs=[]\n",
    "        batch_acts=[]\n",
    "        batch_rews_d=[]\n",
    "        batch_rews_c=[]\n",
    "        batch_waiting_time=[]\n",
    "        self.discount_array = [0.7,0.3]\n",
    "        action_d=np.array([0] *self.env.nb_car* self.env.nb_ped)\n",
    "        action_d_light=np.array([0] *self.env.nb_car)\n",
    "        for ep in range(nbr_episodes):\n",
    "            need_new_d=True\n",
    "            save_batch=False\n",
    "            state,_ = self.env.reset()\n",
    "            if(choix):\n",
    "                self.choix_test()\n",
    "                state = self.env.get_state()\n",
    "            prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "            nb_ped=state[\"env\"][1]\n",
    "            for step_ep in range(self.max_steps): \n",
    "\n",
    "                if(need_new_d):\n",
    "                    ep_rews = []\n",
    "                    episodic_reward = np.array([0.]*self.nb_cars)\n",
    "                    action_all_d=np.array([])\n",
    "                    action_all_d_light=np.array([])\n",
    "                    for i in range(self.nb_cars):\n",
    "                        for j in range(self.env.nb_ped):\n",
    "                            new_prev_state = self.obs_car_ped_d(prev_state,i,j)\n",
    "                            parameters_based = torch.squeeze(actor_net_choice(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                              dim=0).float()))\n",
    "                            parameters_based=torch.squeeze(parameters_based)\n",
    "                            parameters_based=parameters_based.reshape(-1,2)\n",
    "                            action_d2 = torch.argmax(parameters_based,axis=1)#return_softmax\n",
    "                            action_all_d = np.append(action_all_d, action_d2.detach().numpy())\n",
    "                        action_all_d_light=np.append(action_all_d_light,action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "                    #print(2*action_all_d-1)\n",
    "                action_d=(2*action_all_d-1)\n",
    "                action_d_light=(2*action_all_d-1)\n",
    "                need_new_d=False\n",
    "                action_all_c=np.array([])\n",
    "                with torch.no_grad():\n",
    "                    for i in range(self.nb_cars):\n",
    "                        action_c_numpy=np.array(self.env.car_b[1,0])\n",
    "                        for p in range(self.env.nb_ped):\n",
    "                            new_prev_state=self.obs_car_ped(prev_state,i,p)\n",
    "                            if(new_prev_state[7]):\n",
    "                                new_action_c=torch.tensor(max(min((self.env.speed_limit-new_prev_state[0])/self.env.dt,self.env.car_b[1,0]),self.env.car_b[0,0]))\n",
    "                            else:\n",
    "                                if(action_d[i*self.env.nb_ped+p]<=0):\n",
    "                                    new_action_c = torch.squeeze(actor_net_cross(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                                else:\n",
    "                                    new_action_c = torch.squeeze(actor_net_wait(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                            if(new_action_c.dim()==0):\n",
    "                                new_action_c=torch.unsqueeze(new_action_c,dim=0)\n",
    "                            action_c_numpy=min(action_c_numpy,new_action_c.detach().numpy())\n",
    "                            action_c_numpy=min(action_c_numpy,(10.0-new_prev_state[0])/(self.dt))\n",
    "                        action_all_c=np.append(action_all_c, action_c_numpy)\n",
    "                    action_all=np.append(action_all_c, action_d_light)\n",
    "                    \n",
    "                    state, reward, done, trunc, _ = self.env.step(action_all)\n",
    "                    batch_obs.append(prev_state)\n",
    "                    batch_acts.append(action_all_c) #2 actions\n",
    "                    episodic_reward = np.minimum(episodic_reward,self.env.reward_light)\n",
    "                    ep_rews.append(reward)\n",
    "                    if(state[\"env\"][1]!=nb_ped):\n",
    "                        need_new_d=True\n",
    "                        save_batch=True\n",
    "                    prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "                    nb_ped=state[\"env\"][1]\n",
    "                \n",
    "                if(save_batch or done):\n",
    "                    for ped in self.env.pedestrian:\n",
    "                        batch_waiting_time.append(ped.waiting_time)\n",
    "                    batch_rews_c.append(ep_rews)\n",
    "                    batch_rews_d.append(episodic_reward)\n",
    "                save_batch=False\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "        batch_rews_c_final=[]\n",
    "        for ep_rews in reversed(batch_rews_c):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rews_c_final.insert(0,rew)\n",
    "        t_batch_obs=torch.tensor(np.array(batch_obs), dtype=torch.float)\n",
    "        t_batch_acts=torch.tensor(np.array(batch_acts), dtype=torch.float)\n",
    "        t_batch_rews_c=torch.tensor(batch_rews_c_final, dtype=torch.float)\n",
    "        t_batch_rews_d=torch.tensor(batch_rews_d, dtype=torch.float)\n",
    "        t_batch_waiting_time=torch.tensor(batch_waiting_time, dtype=torch.float)\n",
    "        return t_batch_obs, t_batch_acts, t_batch_rews_c, t_batch_rews_d, t_batch_waiting_time\n",
    "\n",
    "    \n",
    "    def iterations_dataset(self, actor_net_cross, actor_net_wait, actor_net_choice, nbr_episodes):\n",
    "        \"\"\"\n",
    "        Iterate on the environment.\n",
    "        :param actor_net: current policy (actor NN)\n",
    "        :param nbr_episodes: episode number\n",
    "        :return: Tensors; state batch, action batch\n",
    "        \"\"\"\n",
    "        batch_obs=[]\n",
    "        batch_acts=[]\n",
    "        batch_acts_d=[]\n",
    "        batch_rews_d=[]\n",
    "        batch_rews_c=[]\n",
    "        batch_waiting_time=[]\n",
    "        self.discount_array = [0.7,0.3]\n",
    "        action_d=np.array([0] *self.env.nb_car* self.env.nb_ped)\n",
    "        action_d_light=np.array([0] *self.env.nb_car)\n",
    "        file = open(\"test_data_23.pickle\",'rb')\n",
    "        env_dataset = pickle.load(file)\n",
    "        for ep in range(nbr_episodes):\n",
    "            need_new_d=True\n",
    "            save_batch=False\n",
    "            self.env=env_dataset[ep]\n",
    "            state = self.env.get_state()#state,_ = self.env.reset()\n",
    "            prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "            nb_ped=state[\"env\"][1]\n",
    "            for step_ep in range(self.max_steps): \n",
    "\n",
    "                if(need_new_d):\n",
    "                    ep_rews = []\n",
    "                    episodic_reward = np.array([0.]*self.nb_cars)\n",
    "                    action_all_d=np.array([])\n",
    "                    action_all_d_light=np.array([])\n",
    "                    for i in range(self.nb_cars):\n",
    "                        for j in range(self.env.nb_ped):\n",
    "                            new_prev_state = self.obs_car_ped_d(prev_state,i,j)\n",
    "                            parameters_based = torch.squeeze(actor_net_choice(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                              dim=0).float()))\n",
    "                            parameters_based=torch.squeeze(parameters_based)\n",
    "                            parameters_based=parameters_based.reshape(-1,2)\n",
    "                            action_d2 = torch.argmax(parameters_based,axis=1)#return_softmax\n",
    "                            action_all_d = np.append(action_all_d, action_d2.detach().numpy())\n",
    "                        action_all_d_light=np.append(action_all_d_light,action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "                action_d=(2*action_all_d-1)\n",
    "                action_d_light=(2*action_all_d_light-1)\n",
    "                need_new_d=False\n",
    "                action_all_c=np.array([])\n",
    "                with torch.no_grad():\n",
    "                    for i in range(self.nb_cars):\n",
    "                        action_c_numpy=np.array(self.env.car_b[1,0])\n",
    "                        for p in range(self.env.nb_ped):\n",
    "                            new_prev_state=self.obs_car_ped(prev_state,i,p)\n",
    "                            if(new_prev_state[7]):\n",
    "                                new_action_c=torch.tensor(max(min((self.env.speed_limit-new_prev_state[0])/self.env.dt,self.env.car_b[1,0]),self.env.car_b[0,0]))\n",
    "                            else:\n",
    "                                if(action_d[i*self.env.nb_ped+p]<=0):\n",
    "                                    new_action_c = torch.squeeze(actor_net_cross(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                                else:\n",
    "                                    new_action_c = torch.squeeze(actor_net_wait(torch.unsqueeze(torch.tensor(new_prev_state), dim=0).float()))\n",
    "                            if(new_action_c.dim()==0):\n",
    "                                new_action_c=torch.unsqueeze(new_action_c,dim=0)\n",
    "                            action_c_numpy=min(action_c_numpy,new_action_c.detach().numpy())\n",
    "                            action_c_numpy=min(action_c_numpy,(10.0-new_prev_state[0])/(self.dt))\n",
    "                        action_all_c=np.append(action_all_c, action_c_numpy)\n",
    "                    action_all=np.append(action_all_c, action_d_light)\n",
    "                    \n",
    "                    state, reward, done, trunc, _ = self.env.step(action_all)\n",
    "                    batch_obs.append(prev_state)\n",
    "                    batch_acts.append(action_all_c) #2 actions\n",
    "                    episodic_reward = np.minimum(episodic_reward,self.env.reward_light)\n",
    "                    ep_rews.append(reward)\n",
    "                    if(state[\"env\"][1]!=nb_ped):\n",
    "                        need_new_d=True\n",
    "                        save_batch=True\n",
    "                    prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "                    nb_ped=state[\"env\"][1]\n",
    "                \n",
    "                if(save_batch or done):\n",
    "                    for ped in self.env.pedestrian:\n",
    "                        batch_waiting_time.append(ped.waiting_time)\n",
    "                    batch_rews_c.append(ep_rews)\n",
    "                    batch_rews_d.append(episodic_reward)\n",
    "                    batch_acts_d.append(action_d)\n",
    "                    #print(action_d)\n",
    "                save_batch=False\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "        batch_rews_c_final=[]\n",
    "        for ep_rews in reversed(batch_rews_c):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rews_c_final.insert(0,rew)\n",
    "        t_batch_obs=torch.tensor(np.array(batch_obs), dtype=torch.float)\n",
    "        t_batch_acts=torch.tensor(np.array(batch_acts), dtype=torch.float)\n",
    "        t_batch_acts_d=torch.tensor(np.array(batch_acts_d), dtype=torch.float)\n",
    "        t_batch_rews_c=torch.tensor(batch_rews_c_final, dtype=torch.float)\n",
    "        t_batch_rews_d=torch.tensor(batch_rews_d, dtype=torch.float)\n",
    "        t_batch_waiting_time=torch.tensor(batch_waiting_time, dtype=torch.float)\n",
    "        np.savetxt('decisions_d_dataset.txt', np.array(t_batch_acts_d), fmt='%d')\n",
    "        return t_batch_obs, t_batch_acts, t_batch_rews_c, t_batch_rews_d, t_batch_waiting_time\n",
    "\n",
    "    def iterations_rand(self, actor_net_cross, actor_net_wait, actor_net_choice, cov_mat, cov_mat_d, batch_size, random_rate=0.05):\n",
    "        \"\"\"\n",
    "        Iterate on the environment.\n",
    "        :param actor_net: current policy (actor NN)\n",
    "        :param cov_mat: covariance matrix used for exploration\n",
    "        :param batch_size: batch size\n",
    "        :return: Tensors; state batch, action batch, log_proba batch\n",
    "        \"\"\"\n",
    "        t = 0\n",
    "        error=False\n",
    "        ep_rews = []\n",
    "        ep_probas=[]\n",
    "        ep_actions=[]\n",
    "        ep_obs=[]\n",
    "        ep_probas_d=[]\n",
    "        ep_actions_d=[]\n",
    "        ep_obs_d=[]\n",
    "        action_d=np.array([0] *self.env.nb_car* self.env.nb_ped)\n",
    "        action_d_light=np.array([0] *self.env.nb_car)\n",
    "        episodic_reward = np.array([0.]*self.nb_cars)\n",
    "        while t<batch_size:\n",
    "            need_new_d=True\n",
    "            save_batch=False\n",
    "            state,_ = self.env.reset()\n",
    "            prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "            nb_ped=state[\"env\"][1]\n",
    "            for step_ep in range(self.max_steps): \n",
    "                if(need_new_d):\n",
    "                    ep_rews = []\n",
    "                    ep_probas=[]\n",
    "                    ep_actions=[]\n",
    "                    ep_obs=[]\n",
    "                    ep_obs_d=[]\n",
    "                    ep_probas_d=[]\n",
    "                    ep_actions_d=[]\n",
    "                    episodic_reward = np.array([0.]*self.nb_cars)\n",
    "                    #state_all_d=np.array([])\n",
    "                    action_all_d=np.array([])\n",
    "                    action_all_d_light=np.array([])\n",
    "                    log_proba_all_d=np.array([])\n",
    "                    log_proba_all_d_light=np.array([])\n",
    "                    new_prev_state_all_d=np.array([])\n",
    "                    new_prev_state_all_d_light=np.array([])\n",
    "                    for i in range(self.env.nb_car):\n",
    "                        for j in range(self.env.nb_ped):\n",
    "                            #adaptation state for ped_car interaction (+info other vehicle)\n",
    "                            new_prev_state = self.obs_car_ped_d(prev_state,i,j) # for 1 ped and 1 vehicule+info other vehicle\n",
    "                            parameters_based = torch.squeeze(actor_net_choice(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                              dim=0).float()))\n",
    "                            distribution_d=Categorical(parameters_based)\n",
    "                            action_d=distribution_d.sample()\n",
    "                            log_proba_d=distribution_d.log_prob(action_d)\n",
    "                            log_proba_all_d = np.append(log_proba_all_d,log_proba_d.detach().numpy())\n",
    "                            action_all_d = np.append(action_all_d, action_d.detach().numpy())\n",
    "                            new_prev_state_all_d = np.append(new_prev_state_all_d, new_prev_state)\n",
    " \n",
    "                        new_prev_state_all_d=new_prev_state_all_d.reshape(-1,self.shape_env_d)\n",
    "                        new_action_light=action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)]\n",
    "                        action_all_d_light = np.append(action_all_d_light,\n",
    "                                                     action_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "                        log_proba_all_d_light = np.append(log_proba_all_d_light,\n",
    "                                                          log_proba_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "                        new_prev_state_all_d_light=np.append(new_prev_state_all_d_light,\n",
    "                                                             new_prev_state_all_d[i*self.env.nb_ped+self.closest_ped_d(prev_state,i)])\n",
    "                    action_d=(2*action_all_d-1) # we train on light\n",
    "                    action_d_light=(2*action_all_d_light-1)\n",
    "                    ep_actions_d.append(action_all_d_light)\n",
    "                    ep_probas_d.append(log_proba_all_d_light)\n",
    "                    ep_obs_d.append(new_prev_state_all_d_light)\n",
    "                    need_new_d=False\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    action_all_c=np.array([])\n",
    "                    log_proba_all_c=np.array([])\n",
    "                    new_prev_state_all_c=np.array([])\n",
    "                    for i in range(self.nb_cars):\n",
    "                        action_c_tensor=torch.tensor(self.env.car_b[1,0])\n",
    "                        state_c_tensor=self.obs_car_ped(prev_state,i,0)\n",
    "                        for p in range(self.env.nb_ped):\n",
    "                            new_prev_state=self.obs_car_ped(prev_state,i,p)\n",
    "                            if(action_d[i*self.env.nb_ped+p]<=0):\n",
    "                                parameters_based_c=torch.squeeze(actor_net_cross(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                                   dim=0).float()))\n",
    "                            else:\n",
    "                                parameters_based_c = torch.squeeze(actor_net_wait(torch.unsqueeze(torch.tensor(new_prev_state),\n",
    "                                                                                                  dim=0).float()))\n",
    "                            if(parameters_based_c.dim()==0):\n",
    "                                parameters_based_c=torch.unsqueeze(parameters_based_c,dim=0)\n",
    "                            action_c_tensor=torch.min(action_c_tensor,parameters_based_c) # need to remove passed pedestrian in the decision?\n",
    "                            if (parameters_based_c==action_c_tensor):\n",
    "                                state_c_tensor=new_prev_state\n",
    "                        distribution_p = MultivariateNormal(action_c_tensor, cov_mat)\n",
    "                        action_c = distribution_p.sample()\n",
    "                        log_proba = distribution_p.log_prob(action_c)\n",
    "                        action_c_numpy = action_c.detach().numpy()\n",
    "                        log_proba_all_c = np.append(log_proba_all_c,log_proba.detach().numpy())\n",
    "                        action_all_c = np.append(action_all_c, action_c_numpy)\n",
    "                        new_prev_state_all_c = np.append(new_prev_state_all_c, state_c_tensor)\n",
    "                        \n",
    "                    action_all=np.append(action_all_c, action_d_light)\n",
    "                    state, rewards, done, trunc, _ = self.env.step(action_all)\n",
    "                    episodic_reward = np.minimum(episodic_reward,self.env.reward_light)\n",
    "                    ep_obs.append(new_prev_state_all_c)\n",
    "                    ep_actions.append(action_all_c)\n",
    "                    ep_probas.append(log_proba_all_c)\n",
    "                    ep_rews.append(rewards)\n",
    "                    if(state[\"env\"][1]!=nb_ped):# or (not error and self.env.error_scenario)):\n",
    "                        if(not error and self.env.error_scenario):\n",
    "                            error=True\n",
    "                            self.env.error_scenario=False\n",
    "                            \n",
    "                        print(\"Rebuild plan: \",error)\n",
    "                        need_new_d=True\n",
    "                        save_batch=True\n",
    "                    prev_state = np.concatenate([i.flatten() for i in list(state.values())])\n",
    "                    nb_ped=state[\"env\"][1]\n",
    "                if(save_batch + done):\n",
    "                    ep_probas=np.array(ep_probas).reshape(-1,self.nb_cars)\n",
    "                    ep_actions=np.array(ep_actions).reshape(-1,self.nb_cars)\n",
    "                    ep_obs=np.array(ep_obs).reshape(-1,self.nb_cars,self.shape_env)\n",
    "                    ep_rews=np.array(ep_rews).reshape(-1,self.nb_cars)\n",
    "                    ep_probas_d=np.array(ep_probas_d).reshape(-1,self.nb_cars)#.reshape(-1,self.nb_cars)\n",
    "                    ep_actions_d=np.array(ep_actions_d).reshape(-1,self.nb_cars)#.reshape(-1,self.nb_cars)\n",
    "                    ep_obs_d=np.array(ep_obs_d).reshape(-1,self.nb_cars,self.shape_env_d)\n",
    "                    \n",
    "                    for i in range(self.nb_cars):  \n",
    "                        if(action_d[i]<=0):\n",
    "                            self.batch_rews_cross.append(ep_rews[:,i])\n",
    "                            self.batch_log_probs_cross.extend(ep_probas[:,i])\n",
    "                            self.batch_acts_cross.extend(ep_actions[:,i:i+1])\n",
    "                            self.batch_obs_cross.extend(ep_obs[:,i])\n",
    "                        else:\n",
    "                            self.batch_rews_wait.append(ep_rews[:,i])\n",
    "                            self.batch_log_probs_wait.extend(ep_probas[:,i])\n",
    "                            self.batch_acts_wait.extend(ep_actions[:,i:i+1])\n",
    "                            self.batch_obs_wait.extend(ep_obs[:,i])\n",
    "                            \n",
    "                        self.batch_rews_choice.append(episodic_reward[i:i+1])\n",
    "                        self.batch_log_probs_choice.extend(ep_probas_d[:,i])\n",
    "                        self.batch_acts_choice.extend(ep_actions_d[:,i:i+1])\n",
    "                        self.batch_obs_choice.extend(ep_obs_d[:,i])\n",
    "                        \n",
    "                save_batch=False\n",
    "                t += 1\n",
    "                if done:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "    def change_obs(self, obs, num_car):\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.nb_cars)\n",
    "        new_obs=np.copy(obs)\n",
    "        new_obs[:size_cardata]=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        new_obs[num_car*size_cardata:(num_car+1)*size_cardata]=obs[:size_cardata]\n",
    "        return new_obs\n",
    "    \n",
    "    def is_in_cross(self, car_line, ped_pos, ped_dir, cross_lines, lines):\n",
    "        cross= (cross_lines*2) /lines\n",
    "        line_start, line_end = (-cross_lines)+cross*(car_line), (-cross_lines)+cross*(car_line+1)\n",
    "        dist_to_start=(ped_pos-line_start)*(ped_dir>0) + (line_end-ped_pos)*(ped_dir<0)\n",
    "        return (ped_pos>line_start and ped_pos<line_end),dist_to_start\n",
    "        \n",
    "    def leave_cross(self,  car_line, ped_pos, ped_dir, cross_lines, lines):\n",
    "        cross= (cross_lines*2) /lines\n",
    "        line_start, line_end = (-cross_lines)+cross*(car_line), (-cross_lines)+cross*(car_line+1)\n",
    "        #dist_to_end=(ped_pos-line_end)*(ped_dir>0) + (line_start-ped_pos)*(ped_dir<0)\n",
    "        if(ped_dir==-1):\n",
    "            return (ped_pos<line_start) , (line_start-ped_pos)\n",
    "        else:\n",
    "            return (ped_pos>line_end) , (ped_pos-line_end)\n",
    "\n",
    "    def obs_car_ped(self, obs, num_car, num_ped): #11\n",
    "        new_obs=np.array([])\n",
    "        size_car=int(self.env.observation_space[\"car\"].shape[0])\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.env.nb_car)\n",
    "        size_ped=int(self.env.observation_space[\"ped\"].shape[0])\n",
    "        size_peddata=int(self.env.observation_space[\"ped\"].shape[0]/self.env.nb_ped)\n",
    "        size_env=int(self.env.observation_space[\"env\"].shape[0])\n",
    "        # respectively car acceleration (0), car_speed(1), car speed diff (2), car position (3), light(4), line (5)\n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        # respectively  pedestrian speed x (0), pedestrian speed y (1), pedestrian position x(2)\n",
    "        #                position y (3), dl(4), leave CZ(5), in CZ (6), exist(7), direction(8)\n",
    "        ped_data=obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata]\n",
    "        #sizealllines (0), nb_ped (1), lines \n",
    "        env_data=obs[size_car:size_car+size_env]\n",
    "        new_obs=np.append(new_obs,[car_data[1],car_data[2]])#car_data[0], a voir pour avoir un numero de ligne % position du pieton\n",
    "        #acc speed, diff speed, car speed diff , line (4 data)\n",
    "        crossing, dist_start=self.is_in_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        end_cross, dist_end=self.leave_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        time_to_collision=min(10.0,(ped_data[2]-car_data[3])/max(car_data[1]-ped_data[0],0.01))*(ped_data[2]>car_data[3])+10.0*(ped_data[2]<=car_data[3])\n",
    "        new_obs=np.append(new_obs,[ped_data[1],ped_data[2]>car_data[3], ped_data[2]-car_data[3], ped_data[4],\n",
    "                                   crossing, end_cross, dist_start, dist_end, time_to_collision])#(9 data)\n",
    "        # speed y, is in front, distance ped-AV, safety factor,  ped in CZ or finished,\n",
    "        # distance to start, distance to end cross, time to collision\n",
    "        new_obs=np.append(new_obs,[env_data[0],env_data[2]])\n",
    "        # crossing size , lines (2 data)\n",
    "        \n",
    "        #add time to collision: min(10.0,(ped_data[2]-car_data[3])/(car_data[1]-ped_data[0])\n",
    "        return new_obs.flatten()\n",
    "    \n",
    "    def obs_car_ped_d(self, obs, num_car, num_ped):\n",
    "        new_obs=np.array([])\n",
    "        size_car=int(self.env.observation_space[\"car\"].shape[0])\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.env.nb_car)\n",
    "        size_ped=int(self.env.observation_space[\"ped\"].shape[0])\n",
    "        size_peddata=int(self.env.observation_space[\"ped\"].shape[0]/self.env.nb_ped)\n",
    "        size_env=int(self.env.observation_space[\"env\"].shape[0])\n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        env_data=obs[size_car:size_car+size_env]\n",
    "        new_obs=np.append(new_obs,[car_data[1],car_data[2]])#car_data[0],\n",
    "        #acc speed, diff speed, car speed diff , line (4 data)\n",
    "        ped_data=obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata]\n",
    "        for num_car_i in range(self.env.nb_car):\n",
    "            if(num_car_i!=num_car):\n",
    "                car_data2=obs[num_car_i*size_cardata:(num_car_i+1)*size_cardata]\n",
    "                new_obs=np.append(new_obs,[car_data2[1],ped_data[2]>car_data2[3],(ped_data[2]-car_data2[3]),\n",
    "                                           car_data2[4], car_data2[5]-car_data[5]]) \n",
    "                # speed, is in front,diff position, light, line (5 data) manque position relative % au vehicule?\n",
    "                \n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        crossing, dist_start=self.is_in_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        end_cross, dist_end=self.leave_cross(car_data[5],ped_data[3],ped_data[8],env_data[0],env_data[2])\n",
    "        \n",
    "        new_obs=np.append(new_obs,[ped_data[1], ped_data[2]>car_data[3], (ped_data[2]-car_data[3]), ped_data[4],\n",
    "                                   crossing, end_cross, dist_start, dist_end]) \n",
    "        # speed y, is in front, distance to ped, safety factor, ped in CZ or finished,\n",
    "        #distance to start, distance to end cross #(8 data)\n",
    "        new_obs=np.append(new_obs,[env_data[0],env_data[2] ])\n",
    "        #size of the road, number of lines (2 data)\n",
    "        return new_obs.flatten()\n",
    "    \n",
    "    #decision for light\n",
    "    def closest_ped_d(self, obs, num_car):\n",
    "        size_env=int(self.env.observation_space[\"env\"].shape[0])\n",
    "        size_car=int(self.env.observation_space[\"car\"].shape[0])\n",
    "        size_cardata=int(self.env.observation_space[\"car\"].shape[0]/self.env.nb_car)\n",
    "        size_peddata=int(self.env.observation_space[\"ped\"].shape[0]/self.env.nb_ped)\n",
    "        min_ped=0\n",
    "        car_data=obs[num_car*size_cardata:(num_car+1)*size_cardata]\n",
    "        min_dist_ped=obs[size_car+size_env+2]-car_data[3]\n",
    "        for num_ped in range(self.env.nb_ped):\n",
    "            ped_data=obs[size_car+size_env+num_ped*size_peddata:size_car+size_env+(num_ped+1)*size_peddata]\n",
    "            if(ped_data[2]-car_data[3]<min_dist_ped):\n",
    "                min_dist_ped=ped_data[2]-car_data[3]\n",
    "                min_ped=num_ped\n",
    "        return min_ped\n",
    "    \n",
    "    def choix_test(self):\n",
    "        self.env.cross=3.\n",
    "        self.env.reset_pedestrian(0, 0., 1.25, 0., -1.0, 0, -1, self.env.cross)\n",
    "        self.env.reset_cars(0, self.env.state[\"car\"][1], -45, 0., 0.)\n",
    "        self.env.reset_cars(1, self.env.state[\"car\"][1], -22, 0., 1.)\n",
    "        \n",
    "    def immediate_rewards(self):\n",
    "        \"\"\"\n",
    "        Immediate rewards\n",
    "        :return: Tensor; batch reward\n",
    "        \"\"\"\n",
    "        batch_rew_cross = []\n",
    "        batch_rew_wait = []\n",
    "        batch_rew_choice= []\n",
    "        for ep_rews in reversed(self.batch_rews_cross):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rew_cross.insert(0,rew)\n",
    "        for ep_rews in reversed(self.batch_rews_wait):\n",
    "            for rew in reversed(ep_rews):\n",
    "                batch_rew_wait.insert(0,rew)\n",
    "        batch_rew_choice=self.batch_rews_choice\n",
    "        batch_rew_choice=np.array(batch_rew_choice)\n",
    "        batch_rew_wait=np.array(batch_rew_wait)\n",
    "        batch_rew_cross=np.array(batch_rew_cross)\n",
    "        return torch.tensor(batch_rew_cross, dtype=torch.float),torch.tensor(batch_rew_wait, dtype=torch.float), torch.tensor(batch_rew_choice, dtype=torch.float)\n",
    "    \n",
    "    def futur_rewards(self):\n",
    "        \"\"\"\n",
    "        Expected futures rewards\n",
    "        :return: Tensor; batch reward-to-go\n",
    "        \"\"\"\n",
    "        batch_rtgs_cross = []\n",
    "        batch_rtgs_wait = []\n",
    "        batch_rtgs_choice= []\n",
    "        for ep_rews in reversed(self.batch_rews_cross):\n",
    "            episodic_reward=0.0\n",
    "            for rew in reversed(ep_rews):\n",
    "                episodic_reward= rew + 0.99*episodic_reward\n",
    "                batch_rtgs_cross.insert(0,episodic_reward)\n",
    "        for ep_rews in reversed(self.batch_rews_wait):\n",
    "            episodic_reward=0.0\n",
    "            for rew in reversed(ep_rews):\n",
    "                episodic_reward= rew + 0.99*episodic_reward\n",
    "                batch_rtgs_wait.insert(0,episodic_reward)\n",
    "        batch_rtgs_choice=self.batch_rews_choice\n",
    "        batch_rtgs_choice=np.array(batch_rtgs_choice)\n",
    "        batch_rtgs_wait=np.array(batch_rtgs_wait)\n",
    "        batch_rtgs_cross=np.array(batch_rtgs_cross)\n",
    "        return torch.tensor(batch_rtgs_cross, dtype=torch.float), torch.tensor(batch_rtgs_wait, dtype=torch.float), torch.tensor(batch_rtgs_choice, dtype=torch.float)\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "#4) Algorithm PPO\n",
    "\n",
    "def multiply(action, param):\n",
    "    res=torch.tensor(1.)\n",
    "    for i in range(len(action)):\n",
    "        distrib= Categorical(param[i])\n",
    "        res=res*distrib.log_prob(action)\n",
    "    return res.detach().numpy()\n",
    "\n",
    "class Algo_PPO():\n",
    "    \"\"\" \n",
    "    PPO algorithm : training and testing\n",
    "    :param policy_class: policy (actor model)\n",
    "    :param env: environment\n",
    "    :param hyperparameters: other hyperparameters\n",
    "    \"\"\"\n",
    "    def __init__(self, policy_class, env, **hyperparameters):\n",
    "        \n",
    "        self._init_hyperparameters(hyperparameters)\n",
    "        self.max_steps=env.max_episode\n",
    "        self.actor_net_cross = policy_class(self.num_states_c, self.num_actions, 1,\n",
    "                                            nb_car=self.nb_cars,mean=self.mean,std=self.std)\n",
    "        self.actor_net_wait = policy_class(self.num_states_c, self.num_actions, 1,\n",
    "                                           nb_car=self.nb_cars,mean=self.mean,std=self.std)\n",
    "        self.actor_net_choice = policy_class(self.num_states_d, 2, 2) # only one we need two nb_car\n",
    "        self.critic_net_cross = policy_class(self.num_states_c, 1, 0)\n",
    "        self.critic_net_wait = policy_class(self.num_states_c, 1, 0)\n",
    "        self.critic_net_choice = policy_class(self.num_states_d, 1, 0)\n",
    "        self.optimizer_critic_cross = optim.Adam(self.critic_net_cross.parameters(), self.critic_lr)\n",
    "        self.optimizer_critic_wait = optim.Adam(self.critic_net_wait.parameters(), self.critic_lr)\n",
    "        self.optimizer_critic_choice = optim.Adam(self.critic_net_choice.parameters(), self.critic_d_lr)\n",
    "        self.optimizer_actor_cross = optim.Adam(self.actor_net_cross.parameters(), self.actor_lr)\n",
    "        self.optimizer_actor_wait = optim.Adam(self.actor_net_wait.parameters(), self.actor_lr)\n",
    "        self.optimizer_actor_choice = optim.Adam(self.actor_net_choice.parameters(), self.actor_d_lr)\n",
    "        self.value_std = 0.5\n",
    "        self.value_std_d = 0.1\n",
    "        self.cov_var = torch.full(size=(self.num_actions,), fill_value=self.value_std)\n",
    "        self.cov_mat = torch.diag(self.cov_var)\n",
    "        self.cov_var_d = torch.full(size=(2*self.nb_cars,), fill_value=self.value_std_d)\n",
    "        self.cov_mat_d = torch.diag(self.cov_var_d)\n",
    "        self.rollout = Env_rollout(env, self.nb_cars, self.max_steps, self.dt)\n",
    "        self.ep_reward_cross=[]\n",
    "        self.ep_reward_wait=[]\n",
    "        self.ep_reward_choice=[]\n",
    "        self.ep_scenario_balance=[]\n",
    "    \n",
    "    def evaluate(self, nbr_episodes,choix=False):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :param nbr_episodes: episode number \n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch = self.rollout.iterations(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, nbr_episodes, choix)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch\n",
    "    \n",
    "    def evaluate_dataset(self, nbr_episodes):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :param nbr_episodes: episode number \n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch = self.rollout.iterations_dataset(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, nbr_episodes)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch, time_stop_batch\n",
    "    \n",
    "    def tests_cross_wait(self):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch = self.rollout.tests_cross_wait(self.actor_net_cross, self.actor_net_wait)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch\n",
    "    \n",
    "    def tests_choice(self):\n",
    "        \"\"\"\n",
    "        Testing\n",
    "        :return: state batch, action batch, and reward batch\n",
    "        \"\"\"\n",
    "        self.rollout.reset()\n",
    "        state_batch, action_batch, rew_c_batch, rew_d_batch = self.rollout.tests_choice(self.actor_net_cross, self.actor_net_wait)\n",
    "        return state_batch, action_batch, rew_c_batch, rew_d_batch\n",
    "    \n",
    "    def train_model_c(self, actor, critic, opti_actor, opti_critic, state_batch, action_batch, log_prob_batch, rtgs_batch, cov_mat):\n",
    "        V_batch = torch.squeeze(critic(torch.tensor(state_batch).float()))\n",
    "        rtgs_batch=rtgs_batch.flatten()\n",
    "        advantage_batch = rtgs_batch - V_batch\n",
    "        advantage_batch = (advantage_batch - advantage_batch.mean()) / (advantage_batch.std() + 1e-10)\n",
    "\n",
    "        parameters_batch = torch.squeeze(actor(torch.tensor(state_batch).float()))\n",
    "        if(parameters_batch.dim()==1):\n",
    "            parameters_batch=torch.unsqueeze(parameters_batch, dim=1)\n",
    "        if(len(cov_mat)>1):\n",
    "            parameters_batch=parameters_batch.reshape(-1,len(cov_mat))\n",
    "            action_batch=torch.tensor(action_batch).reshape(-1,len(cov_mat))\n",
    "        distribution_p = MultivariateNormal(parameters_batch, cov_mat)\n",
    "        log_prob_current_batch = distribution_p.log_prob(torch.tensor(action_batch))\n",
    "        ratio_batch = torch.exp(log_prob_current_batch - torch.tensor(log_prob_batch))\n",
    "        ratio_loss = torch.mul(ratio_batch, advantage_batch)\n",
    "        clip_loss = torch.mul(torch.clamp(ratio_batch, 0.8, 1.2), advantage_batch)\n",
    "        actor_loss = (-torch.min(ratio_loss, clip_loss)).mean()\n",
    "\n",
    "        criterion=nn.MSELoss(reduction='mean')\n",
    "        critic_loss = criterion(V_batch.float(), rtgs_batch.float())\n",
    "        opti_actor.zero_grad()\n",
    "        actor_loss.backward(retain_graph=True)\n",
    "        opti_actor.step()\n",
    "        opti_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opti_critic.step()\n",
    "        \n",
    "        \n",
    "    def train_model_d(self, actor, critic, opti_actor, opti_critic, state_batch, action_batch, log_prob_batch, rtgs_batch, cov_mat):\n",
    "        V_batch = torch.squeeze(critic(torch.tensor(state_batch).float()))\n",
    "        rtgs_batch=rtgs_batch.flatten()\n",
    "        advantage_batch = rtgs_batch - V_batch\n",
    "        advantage_batch = (advantage_batch - advantage_batch.mean()) / (advantage_batch.std() + 1e-10)\n",
    "\n",
    "        parameters_batch = torch.squeeze(actor(torch.tensor(state_batch).float()))\n",
    "        action_batch=torch.tensor(action_batch)#.reshape(-1,2)\n",
    "        if(parameters_batch.dim()==1):\n",
    "            parameters_batch=torch.unsqueeze(parameters_batch, dim=1)\n",
    "        parameters_batch=parameters_batch.reshape(-1,2)\n",
    "        \n",
    "        distribution_p=Categorical(parameters_batch)\n",
    "        log_prob_current_batch = distribution_p.log_prob(torch.tensor(action_batch))\n",
    "        ratio_batch = torch.exp(log_prob_current_batch - torch.tensor(log_prob_batch))\n",
    "        ratio_loss = torch.mul(ratio_batch, advantage_batch)\n",
    "        clip_loss = torch.mul(torch.clamp(ratio_batch, 0.8, 1.2), advantage_batch)\n",
    "        actor_loss = (-torch.min(ratio_loss, clip_loss)).mean()\n",
    "\n",
    "        criterion=nn.MSELoss(reduction='mean')\n",
    "        critic_loss = criterion(V_batch.float(), rtgs_batch.float())\n",
    "        opti_actor.zero_grad()\n",
    "        actor_loss.backward(retain_graph=True)\n",
    "        opti_actor.step()\n",
    "        opti_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opti_critic.step()\n",
    "        \n",
    "        \n",
    "    def train(self, nb_loop):\n",
    "        \"\"\" \n",
    "        Training\n",
    "        :param nb_loop: number of batch iterations\n",
    "        \"\"\"\n",
    "        for ep in range(nb_loop):\n",
    "            self.rollout.reset()\n",
    "            random_rate=0.0\n",
    "            self.rollout.iterations_rand(self.actor_net_cross, self.actor_net_wait, self.actor_net_choice, self.cov_mat, self.cov_mat_d, self.batch_size, random_rate)\n",
    "            rtgs_batch_cross, rtgs_batch_wait, rtgs_batch_choice = self.rollout.futur_rewards()\n",
    "            print(rtgs_batch_cross.shape)\n",
    "            print(rtgs_batch_wait.shape)\n",
    "            for i in range(10): # we could limit the learning if rew<constante\n",
    "                if(len(rtgs_batch_cross)>0):\n",
    "                    self.train_model_c(self.actor_net_cross, self.critic_net_cross, self.optimizer_actor_cross,\n",
    "                                       self.optimizer_critic_cross, np.array(self.rollout.batch_obs_cross),\n",
    "                                       np.array(self.rollout.batch_acts_cross), np.array(self.rollout.batch_log_probs_cross),\n",
    "                                       rtgs_batch_cross, self.cov_mat)\n",
    "                if(len(rtgs_batch_wait)>0):\n",
    "                    self.train_model_c(self.actor_net_wait, self.critic_net_wait, self.optimizer_actor_wait, self.optimizer_critic_wait,\n",
    "                                     np.array(self.rollout.batch_obs_wait), np.array(self.rollout.batch_acts_wait),\n",
    "                                     np.array(self.rollout.batch_log_probs_wait), rtgs_batch_wait, self.cov_mat)\n",
    "            for i in range(10):\n",
    "                self.train_model_d(self.actor_net_choice, self.critic_net_choice, self.optimizer_actor_choice, self.optimizer_critic_choice,\n",
    "                                 np.array(self.rollout.batch_obs_choice), np.array(self.rollout.batch_acts_choice),\n",
    "                                 np.array(self.rollout.batch_log_probs_choice), rtgs_batch_choice, self.cov_mat_d)\n",
    "\n",
    "            rew_cross_batch, rew_wait_batch, rew_choice_batch = self.rollout.immediate_rewards()\n",
    "            if(len(rew_cross_batch)>0):\n",
    "                self.ep_reward_cross.append(rew_cross_batch.mean().numpy())\n",
    "                print(\"Cross not empty\")\n",
    "            if(len(rew_wait_batch)>0):\n",
    "                print(\"Wait not empty\")\n",
    "                self.ep_reward_wait.append(rew_wait_batch.mean().numpy())\n",
    "            self.ep_reward_choice.append(rew_choice_batch.mean().numpy())\n",
    "            print(\"Mean of choices\",rew_choice_batch.mean())\n",
    "            avg_reward_cross = np.mean(self.ep_reward_cross[-10:])\n",
    "            avg_reward_wait = np.mean(self.ep_reward_wait[-10:])\n",
    "            avg_reward_choice = np.mean(self.ep_reward_choice[-10:])\n",
    "            self.rollout.reset()\n",
    "            \n",
    "            print(\"Episode * {} * And Number of steps is ==> {}\".format(ep, ep*self.batch_size))\n",
    "            print(\"Average Cross reward is ==> {}, Average Wait reward is ==> {}\".format(avg_reward_cross, avg_reward_wait))\n",
    "            print(\"Average Choice reward is ==> {}\".format( avg_reward_choice))\n",
    "            print(\"Number Cross is ==> {} and Number Wait is ==> {} \".format(len(rew_cross_batch), len(rew_wait_batch)))\n",
    "            self.ep_scenario_balance.append([len(rew_cross_batch), len(rew_wait_batch)])\n",
    "            self.total_loop = self.total_loop +1\n",
    "        path='load_model/parameters/pappo-acc6-{num_algo:02d}-{name}-step-{epoch:03d}000.npy'\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"reward_cross\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_reward_cross))\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"reward_wait\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_reward_wait))\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"reward_choice\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_reward_choice))\n",
    "        with open(path.format(num_algo=self.num_algo, epoch=int(self.total_loop/1000), name=\"scenario_balance\"), 'wb') as f:\n",
    "            np.save(f, np.array(self.ep_scenario_balance).reshape((-1,2)))\n",
    "        print(\"Complete\")\n",
    "        \n",
    "    def _init_hyperparameters(self, hyperparameters):\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters. \n",
    "        :param hyperparameters: hyperparameter list\n",
    "        \"\"\"\n",
    "        self.num_algo = 1\n",
    "        self.total_loop = 0\n",
    "        self.batch_size = 2048\n",
    "        self.gamma = 0.99\n",
    "        self.critic_lr = 1e-3\n",
    "        self.actor_lr = 3e-4\n",
    "        self.critic_d_lr = 1e-3\n",
    "        self.actor_d_lr = 3e-4\n",
    "        for param, val in hyperparameters.items():\n",
    "            exec('self.' + param + ' = ' + str(val)) #juste trop fort\n",
    "            \n",
    "    def loading(self, num_algo, total_loop):\n",
    "        \"\"\"\n",
    "        Loading NN weights \n",
    "        :param num_algo: algorithm number\n",
    "        :param total_loop: number of total batch iterations\n",
    "        \"\"\"\n",
    "        self.num_algo = num_algo\n",
    "        self.total_loop = total_loop\n",
    "        actor_cross_path = \"load_model/weights/pappo-acc6-cross-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_wait_path = \"load_model/weights/pappo-acc6-wait-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_choice_path = \"load_model/weights/pappo-acc6-choice-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        critic_cross_path = \"load_model/weights/pappo-acc6-cross-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_wait_path = \"load_model/weights/pappo-acc6-wait-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_choice_path = \"load_model/weights/pappo-acc6-choice-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        \n",
    "        self.actor_net_cross.load_state_dict(torch.load(actor_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.actor_net_wait.load_state_dict(torch.load(actor_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.actor_net_choice.load_state_dict(torch.load(actor_choice_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.critic_net_cross.load_state_dict(torch.load(critic_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.critic_net_wait.load_state_dict(torch.load(critic_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)))\n",
    "        self.critic_net_choice.load_state_dict(torch.load(critic_choice_path.format(epoch=int(self.total_loop/10),num_algo=self.num_algo)))\n",
    "        \n",
    "    def loading_curriculum(self, num_actor, num_algo, total_loop):\n",
    "        \"\"\"\n",
    "        Loading NN weights \n",
    "        :param num_algo: number of the algo\n",
    "        :param total_loop: number of total batch iterations\n",
    "        \"\"\"\n",
    "        self.total_loop = total_loop\n",
    "        if(num_actor==0):\n",
    "            actor_cross_path = \"load_model/weights/pappo-acc6-cross-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "            critic_cross_path = \"load_model/weights/pappo-acc6-cross-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "            self.actor_net_cross.load_state_dict(torch.load(actor_cross_path.format(epoch=int(total_loop/10),\n",
    "                                                                                    num_algo=num_algo)))\n",
    "            self.critic_net_cross.load_state_dict(torch.load(critic_cross_path.format(epoch=int(total_loop/10),\n",
    "                                                                                      num_algo=num_algo)))\n",
    "        if(num_actor==1):\n",
    "            actor_wait_path = \"load_model/weights/pappo-acc6-wait-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "            critic_wait_path = \"load_model/weights/pappo-acc6-wait-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "            self.actor_net_wait.load_state_dict(torch.load(actor_wait_path.format(epoch=int(total_loop/10),\n",
    "                                                                                  num_algo=num_algo)))\n",
    "            self.critic_net_wait.load_state_dict(torch.load(critic_wait_path.format(epoch=int(total_loop/10),\n",
    "                                                                                    num_algo=num_algo)))\n",
    "        if(num_actor==2):\n",
    "            actor_choice_path = \"load_model/weights/pappo-acc6-choice-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "            critic_choice_path = \"load_model/weights/pappo-acc6-choice-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "            self.actor_net_choice.load_state_dict(torch.load(actor_choice_path.format(epoch=int(total_loop/10),\n",
    "                                                                                       num_algo=num_algo)))\n",
    "            self.critic_net_choice.load_state_dict(torch.load(critic_choice_path.format(epoch=int(total_loop/10),\n",
    "                                                                                          num_algo=num_algo)))\n",
    "    def saving(self):\n",
    "        \"\"\"\n",
    "        Saving NN weights \n",
    "        \"\"\"\n",
    "        actor_cross_path = \"load_model/weights/pappo-acc6-cross-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_wait_path = \"load_model/weights/pappo-acc6-wait-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        actor_choice_path = \"load_model/weights/pappo-acc6-choice-{num_algo:02d}-actor-step-{epoch:03d}0.pth\"\n",
    "        critic_cross_path = \"load_model/weights/pappo-acc6-cross-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_wait_path = \"load_model/weights/pappo-acc6-wait-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        critic_choice_path = \"load_model/weights/pappo-acc6-choice-{num_algo:02d}-critic-step-{epoch:03d}0.pth\"\n",
    "        \n",
    "        torch.save(self.actor_net_cross.state_dict(), actor_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo))\n",
    "        torch.save(self.actor_net_wait.state_dict(), actor_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "        torch.save(self.actor_net_choice.state_dict(), actor_choice_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo))\n",
    "        torch.save(self.critic_net_cross.state_dict(), critic_cross_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "        torch.save(self.critic_net_wait.state_dict(), critic_wait_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo))\n",
    "        torch.save(self.critic_net_choice.state_dict(), critic_choice_path.format(epoch=int(self.total_loop/10), num_algo=self.num_algo)) \n",
    "\n",
    "#5) Computing part:\n",
    "# Import environment\n",
    "problem = \"Crosswalk_hybrid_multi_naif-v0\"\n",
    "#problem = \"Crosswalk_hybrid_multi_opti7_3-v0\"\n",
    "car_b = np.array([[ -4.0,  10.], [ 2.0, 10.]]) # acceleration and speed of the car\n",
    "ped_b = np.array([[ -0.05, 0.75, 0.0, -3.0], [ 0.05, 1.75, 4., -0.5]]) # speed x, y , position x, y of the pedestrian  [ajout 4 en 3]\n",
    "cross_b = np.array([2.5, 3.0]) # cross min/max, car nbr,  ped nbr\n",
    "print(\"Number of ped\")\n",
    "nb_ped=int(input())\n",
    "#nb_ped=1\n",
    "print(\"Number of car\")\n",
    "nb_car=int(input())\n",
    "#nb_car=1\n",
    "print(\"Number of lines\")\n",
    "nb_lines=int(input())\n",
    "#nb_lines=1\n",
    "print(\"Load model for continuous part?(input number)\")\n",
    "is_loading_c=int(input())\n",
    "print(\"Load model for discrete part?(input number)\")\n",
    "is_loading_d=int(input())\n",
    "print(\"Number steps\")\n",
    "data_size=int(input())\n",
    "\n",
    "max_episode=80\n",
    "env = gym.make(problem, car_b=car_b, ped_b= ped_b, cross_b=cross_b, nb_car=nb_car, nb_ped=nb_ped, nb_lines=nb_lines, dt=0.3,\n",
    "               max_episode=max_episode, simulation=\"sin\")\n",
    "#car_b, ped_b, cross_b, nb_car, nb_ped, nb_lines, dt, max_episode, simulation=\"unif\"\n",
    "#simulation=\"sin\")\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the algorithm\n",
    "num_states_c = 2+9+2#sum([int(env.observation_space[\"car\"].shape[0]/env.nb_car),\n",
    "                 #   int(env.observation_space[\"ped\"].shape[0]/env.nb_ped),\n",
    "                 #   int(env.observation_space[\"env\"].shape[0])])\n",
    "num_states_d = 2+(5*(nb_car-1))+8+2#+5*nb_ped#sum([int(env.observation_space[\"car\"].shape[0]/env.nb_car),\n",
    "                         #int(env.observation_space[\"ped\"].shape[0]),\n",
    "                         #int(env.observation_space[\"env\"].shape[0])])\n",
    "#= sum([math.prod(i.shape) for i in list(env.observation_space.values())])\n",
    "num_actions = 1 # env.action_space.shape[0]\n",
    "num_algo=100*nb_ped+10*nb_car+nb_lines\n",
    "\n",
    "mean =(car_b[1,0]+car_b[0,0])/2.0\n",
    "std =(car_b[1,0]-car_b[0,0])/2.0\n",
    "\n",
    "algo=Algo_PPO(Model_PPO, env, num_algo= num_algo, num_states_c=num_states_c, num_states_d=num_states_d, num_actions=num_actions,\n",
    "              mean=mean, std=std, nb_cars=nb_car, dt=0.3)\n",
    "#algo.loading(1,1000)\n",
    "if(is_loading_c):\n",
    "    algo.loading_curriculum(0,is_loading_c,data_size)\n",
    "    algo.loading_curriculum(1,is_loading_c,data_size)\n",
    "    \n",
    "if(is_loading_d):\n",
    "    algo.loading_curriculum(2,is_loading_d,data_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcfeb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.loading(122,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51fa94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stock an evaluation sample\n",
    "car_feat_size=6\n",
    "env_feat_size=3\n",
    "ped_feat_size=8\n",
    "states, actions, rewards_c, rewards_d, time_stop = algo.evaluate(1000,choix=True)\n",
    "ep_reward_d=rewards_d\n",
    "ep_reward_c=rewards_c\n",
    "lim_car=env.observation_space[\"car\"].shape[0]#env.nb_car*car_feat_size\n",
    "lim_env=env.observation_space[\"env\"].shape[0]#env.nb_ped*ped_feat_size\n",
    "lim_ped=env.observation_space[\"ped\"].shape[0]\n",
    "ep_car = states[:,:lim_car]\n",
    "ep_car = ep_car.reshape(-1,env.nb_car,int(lim_car/env.nb_car))\n",
    "ep_env = states[:,lim_car:lim_car+lim_env]\n",
    "ep_env = ep_env.reshape(-1,lim_env)\n",
    "ep_ped = states[:,lim_car+lim_env:lim_car+lim_env+lim_ped]\n",
    "ep_ped = ep_ped.reshape((-1,env.nb_ped,int(lim_ped/env.nb_ped)))\n",
    "ep_cross=ep_env[:,0]\n",
    "t=0\n",
    "u=0\n",
    "num_episode=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "plt.title(\"Histogram of pedestrian waiting time on sidewalk\")\n",
    "\n",
    "plt.xlabel('Waiting time')\n",
    "plt.ylabel('Percentage')\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "plt.hist(time_stop, bins=10, weights=np.ones(len(time_stop)) / len(time_stop))\n",
    "#plt.savefig(\"HDRL_hist.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3145612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"Display_Data/analyse_yield_122_car_0.csv\", ep_car[:,0], delimiter=\",\")\n",
    "#np.savetxt(\"Display_Data/analyse_yield_122_ped_0.csv\", ep_ped[:,0], delimiter=\",\")\n",
    "#np.savetxt(\"Display_Data/analyse_yield_122_car_1.csv\", ep_car[:,1], delimiter=\",\")\n",
    "#np.savetxt(\"Display_Data/analyse_yield_122_env.csv\", ep_env, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503623f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Showing Vehicle Acceleration Diagram, Vehicle Speed Diagram, Vehicle and Pedestrian Position Diagram\n",
    "#All three over time in an episode\n",
    "if(t+1>=len(ep_cross)):\n",
    "    t=0\n",
    "    u=0\n",
    "t_init=t\n",
    "x_car=[t_init]*env.nb_car\n",
    "x_ped1=[t_init]*env.nb_ped\n",
    "x_ped2=[t_init]*env.nb_ped\n",
    "while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "    for i in range(env.nb_ped):\n",
    "        direction=ep_ped[t_init,i,1]/abs(ep_ped[t_init,i,1])\n",
    "        if(ep_ped[t,i,3]*direction<=-ep_cross[t_init] and ep_ped[t+1,i,3]*direction>-ep_cross[t_init]):\n",
    "            x_ped1[i]=t\n",
    "        if(ep_ped[t,i,3]*direction<=ep_cross[t_init] and ep_ped[t+1,i,3]*direction>ep_cross[t_init]):\n",
    "            x_ped2[i]=t\n",
    "    \n",
    "    for i in range(env.nb_car):\n",
    "        if(ep_car[t,i,3]<ep_ped[t,0,2] and ep_car[t+1,i,3]>ep_ped[t+1,0,2]): #car finish crossing\n",
    "            x_car[i]=t\n",
    "    t+=1\n",
    "    \n",
    "for i in range(env.nb_car):\n",
    "    if(x_car[i]==t_init):\n",
    "        x_car[i]=t\n",
    "cross_lines=ep_env[t_init,0]\n",
    "cross=int((ep_env[t_init,0]*2)/ep_env[t_init,2])\n",
    "\n",
    "ep_time=[i*0.3 for i in range(t-t_init+1)]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3,figsize=(20, 5))\n",
    "ax1.set_title('Car Acceleration')\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "ax1.set_ylabel(\"Acceleration (m/s2)\")\n",
    "ax1.set_ylim(-4.1,2.1)\n",
    "ax1.set_xlim(0,15)\n",
    "for id_car in range(env.nb_car):\n",
    "    ax1.plot(ep_time, ep_car[t_init:t+1,id_car,0],label='car'+str(id_car)) #-ep_cross[t_init]\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "\n",
    "ax3.set_title('Car and Pedestrian Position')\n",
    "ax3.set_xlabel(\"Time (s)\")\n",
    "ax3.set_ylabel(\"Position (m)\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax3.axvline(x=(x_car[id_car]-t_init)*0.3, color='g', linestyle='-.',label='car arrival')\n",
    "    ax3.plot(ep_time, ep_car[t_init:t+1,id_car,3],label='car '+str(id_car)+' (axis x)') #-ep_cross[t_init] -ep_ped[t_init:t+1,0,2]\n",
    "    print(\"light : \",ep_car[t_init+1,id_car,4])\n",
    "for id_ped in range(env.nb_ped):\n",
    "    ax3.plot(ep_time, ep_ped[t_init:t+1,id_ped,3],label='pedestrian '+str(id_ped)+' (axis y)')\n",
    "    direction=ep_ped[t_init,id_ped,1]/abs(ep_ped[t_init,id_ped,1])\n",
    "    if direction:\n",
    "        ax3.axvline(x=(x_ped1[id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "        ax3.axvline(x=(x_ped2[id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "    else:\n",
    "        ax3.axvline(x=(x_ped1[id_ped]-t_init)*0.3,ymin=float(cross_lines-cross),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "        ax3.axvline(x=(x_ped2[id_ped]-t_init)*0.3,ymin=float(cross_lines-cross),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "    ax3.fill_between([(x_ped1[id_ped]-t_init)*0.3,(x_ped2[id_ped]-t_init)*0.3],-20,20, color='b', alpha=0.1,label='pedestrian in crosswalk')\n",
    "ax3.set_ylim(-20,20)\n",
    "ax3.set_xlim(0,15)\n",
    "cross_size=2.0*ep_env[t_init,0]/ep_env[t_init,2]\n",
    "for i in range(int(ep_env[t_init,2])+1):\n",
    "    ax3.axhline(y=-ep_cross[t_init] + i*cross_size , color='r', linestyle='-.')\n",
    "ax3.legend()\n",
    "ax3.grid()\n",
    "\n",
    "ax2.set_title('Car Speed')\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "ax2.set_ylabel(\"Speed (m/s)\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax2.plot(ep_time, ep_car[t_init:t+1,id_car,1],label='car '+str(id_car)) #-ep_cross[t_init]\n",
    "ax2.axhline(y=ep_car[t_init,0,1], color='r', linestyle='-.')\n",
    "ax2.axhline(y=0, color='r', linestyle='-.')\n",
    "ax2.set_xlim(0,27)\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "\n",
    "print(\"Reward discrete \",ep_reward_d[u])\n",
    "t+=1\n",
    "u+=1\n",
    "print(ep_car[t_init,0,3])\n",
    "print(ep_car[t_init,1,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing Vehicle Acceleration Diagram, Vehicle Speed Diagram, Vehicle and Pedestrian Position Diagram\n",
    "#All three over time in an episode\n",
    "#t=0\n",
    "#num_episode=0\n",
    "import copy\n",
    "import pickle\n",
    " \n",
    "def save_object(obj):\n",
    "    try:\n",
    "        with open(\"test_data_23.pickle\", \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as ex:\n",
    "        print(\"Error during pickling object (Possibly unsupported):\", ex)\n",
    "dataset=[]\n",
    "for i in range(1):\n",
    "    env.reset()\n",
    "    dataset.append(copy.deepcopy(env))\n",
    "save_object(dataset)\n",
    "\n",
    "car_feat_size=6\n",
    "env_feat_size=3\n",
    "ped_feat_size=8#.evaluate(1000)\n",
    "states, actions, rewards_c, rewards_d, time_stop = algo.evaluate_dataset(1)#evaluate_dataset(100)\n",
    "#ep_action=states[:,0]\n",
    "#ep_speed_car=states[:,1]\n",
    "#ep_pos_car=states[:,2]\n",
    "#ep_speed_ped=states[:,3]\n",
    "#ep_pos_ped=states[:,4]\n",
    "#ep_cross=states[:,9]\n",
    "ep_reward_d=rewards_d\n",
    "ep_reward_c=rewards_c\n",
    "#ep_light=actions[:,1]\n",
    "\n",
    "lim_car=env.observation_space[\"car\"].shape[0]#env.nb_car*car_feat_size\n",
    "lim_env=env.observation_space[\"env\"].shape[0]#env.nb_ped*ped_feat_size\n",
    "lim_ped=env.observation_space[\"ped\"].shape[0]\n",
    "ep_car = states[:,:lim_car]\n",
    "ep_car = ep_car.reshape(-1,env.nb_car,int(lim_car/env.nb_car))\n",
    "ep_env = states[:,lim_car:lim_car+lim_env]\n",
    "ep_env = ep_env.reshape(-1,lim_env)\n",
    "ep_ped = states[:,lim_car+lim_env:lim_car+lim_env+lim_ped]\n",
    "ep_ped = ep_ped.reshape((-1,env.nb_ped,int(lim_ped/env.nb_ped)))\n",
    "ep_cross=ep_env[:,0]\n",
    "t=0\n",
    "u=0\n",
    "num_episode=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_episode=0\n",
    "#import copy\n",
    "#import pickle\n",
    " \n",
    "#def save_object(obj):\n",
    "#    try:\n",
    "#        with open(\"test_data_23.pickle\", \"wb\") as f:\n",
    "#            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#    except Exception as ex:\n",
    "#        print(\"Error during pickling object (Possibly unsupported):\", ex)\n",
    "#dataset=[]\n",
    "#for i in range(1):\n",
    "#    env.reset()\n",
    "#    dataset.append(copy.deepcopy(env))\n",
    "#save_object(dataset)\n",
    "\n",
    "car_feat_size=6\n",
    "env_feat_size=3\n",
    "ped_feat_size=8#.evaluate(1000)\n",
    "states, actions, rewards_c, rewards_d, time_stop = algo.evaluate(1,choix=True)#evaluate_dataset(100)\n",
    "#ep_action=states[:,0]\n",
    "#ep_speed_car=states[:,1]\n",
    "#ep_pos_car=states[:,2]\n",
    "#ep_speed_ped=states[:,3]\n",
    "#ep_pos_ped=states[:,4]\n",
    "#ep_cross=states[:,9]\n",
    "ep_reward_d=rewards_d\n",
    "ep_reward_c=rewards_c\n",
    "#ep_light=actions[:,1]\n",
    "\n",
    "lim_car=env.observation_space[\"car\"].shape[0]#env.nb_car*car_feat_size\n",
    "lim_env=env.observation_space[\"env\"].shape[0]#env.nb_ped*ped_feat_size\n",
    "lim_ped=env.observation_space[\"ped\"].shape[0]\n",
    "ep_car = states[:,:lim_car]\n",
    "ep_car = ep_car.reshape(-1,env.nb_car,int(lim_car/env.nb_car))\n",
    "ep_env = states[:,lim_car:lim_car+lim_env]\n",
    "ep_env = ep_env.reshape(-1,lim_env)\n",
    "ep_ped = states[:,lim_car+lim_env:lim_car+lim_env+lim_ped]\n",
    "ep_ped = ep_ped.reshape((-1,env.nb_ped,int(lim_ped/env.nb_ped)))\n",
    "ep_cross=ep_env[:,0]\n",
    "t=0\n",
    "u=0\n",
    "num_episode=0\n",
    "if(t+1>=len(ep_cross)):\n",
    "    t=0\n",
    "    u=0\n",
    "t_init=t\n",
    "x_car=[t_init]*env.nb_car\n",
    "x_ped1=[t_init]*env.nb_ped\n",
    "x_ped2=[t_init]*env.nb_ped\n",
    "x_ped3=[t_init]*env.nb_ped\n",
    "while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "    for i in range(env.nb_ped):\n",
    "        direction=ep_ped[t_init,i,1]/abs(ep_ped[t_init,i,1])\n",
    "        #cross_size=2.0*ep_env[t_init,0]/ep_env[t_init,2]\n",
    "        if(ep_ped[t,i,3]*direction<=-ep_cross[t_init] and ep_ped[t+1,i,3]*direction>-ep_cross[t_init]):\n",
    "            x_ped1[i]=t\n",
    "        if(ep_ped[t,i,3]*direction<=0. and ep_ped[t+1,i,3]*direction>0.):\n",
    "            x_ped2[i]=t\n",
    "        if(ep_ped[t,i,3]*direction<=ep_cross[t_init] and ep_ped[t+1,i,3]*direction>ep_cross[t_init]):\n",
    "            x_ped3[i]=t\n",
    "    \n",
    "    for i in range(env.nb_car):\n",
    "        if(ep_car[t,i,3]<ep_ped[t,0,2] and ep_car[t+1,i,3]>ep_ped[t+1,0,2]): #car finish crossing\n",
    "            x_car[i]=t\n",
    "    t+=1\n",
    "    \n",
    "for i in range(env.nb_car):\n",
    "    if(x_car[i]==t_init):\n",
    "        x_car[i]=t\n",
    "cross_lines=ep_env[t_init,0]\n",
    "cross=int((ep_env[t_init,0]*2)/ep_env[t_init,2])\n",
    "x_ped=[x_ped1,x_ped2,x_ped3]\n",
    "ep_time=[i*0.3 for i in range(t-t_init+1)]\n",
    "fig, axs = plt.subplots(2, 2,figsize=(14, 10))\n",
    "for axe_x in range(len(axs)):\n",
    "    axs[axe_x][0].set_title('Car Speed')\n",
    "    axs[axe_x][0].set_xlabel(\"Time (s)\")\n",
    "    axs[axe_x][0].set_ylabel(\"Speed (m/s)\")\n",
    "    #for id_car in range(env.nb_car):\n",
    "    axs[axe_x][0].plot(ep_time, ep_car[t_init:t+1,axe_x,1],label='car '+str(axe_x)) #-ep_cross[t_init]\n",
    "    #ax3.plot(ep_time, ep_speed_car[t_init:t+1],color='r')\n",
    "    axs[axe_x][0].axhline(y=ep_car[t_init,0,1], color='r', linestyle='-.')\n",
    "    axs[axe_x][0].axhline(y=0, color='r', linestyle='-.')\n",
    "    axs[axe_x][0].set_xlim(0,15)\n",
    "    axs[axe_x][0].legend()\n",
    "    axs[axe_x][0].grid()\n",
    "    \n",
    "    axs[axe_x][1].set_title('Car and Pedestrian Position')\n",
    "    axs[axe_x][1].set_xlabel(\"Time (s)\")\n",
    "    axs[axe_x][1].set_ylabel(\"Position (m)\")\n",
    "    axs[axe_x][1].axvline(x=(x_car[axe_x]-t_init)*0.3, color='g', linestyle='-.',label='car arrival')\n",
    "    #print(ep_car[(x_car[id_car]-1):x_car[id_car]+1,0,3])\n",
    "    #print(ep_ped[(x_car[id_car]-1):x_car[id_car]+1,0,3])\n",
    "    #print(ep_env[(x_car[id_car])])\n",
    "    axs[axe_x][1].plot(ep_time, ep_car[t_init:t+1,axe_x,3],label='car '+str(axe_x)+' (axis x)') #-ep_cross[t_init] -ep_ped[t_init:t+1,0,2]\n",
    "    print(\"light : \",ep_car[t_init+1,axe_x,4])\n",
    "    print(\"line : \",ep_car[t_init+1,axe_x,5])\n",
    "    for id_ped in range(env.nb_ped):\n",
    "        axs[axe_x][1].plot(ep_time, ep_ped[t_init:t+1,id_ped,3],label='pedestrian '+str(id_ped)+' (axis y)')\n",
    "        direction=ep_ped[t_init,id_ped,1]/abs(ep_ped[t_init,id_ped,1])\n",
    "        car_lane=int(ep_car[t_init+1,axe_x,5])\n",
    "        print(direction)\n",
    "        if direction>0:\n",
    "            axs[axe_x][1].axvline(x=(x_ped[car_lane][id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "            axs[axe_x][1].axvline(x=(x_ped[car_lane+1][id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "            axs[axe_x][1].fill_between([(x_ped[car_lane][id_ped]-t_init)*0.3,(x_ped[car_lane+1][id_ped]-t_init)*0.3],-20,20, color='b', alpha=0.05,label='pedestrian in lane')\n",
    "\n",
    "        else:\n",
    "            #print(ep_env[t_init,2]-car_lane)\n",
    "            axs[axe_x][1].axvline(x=(x_ped[int(ep_env[t_init,2])-car_lane][id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "            axs[axe_x][1].axvline(x=(x_ped[int(ep_env[t_init,2])-car_lane-1][id_ped]-t_init)*0.3,ymin=float(-cross_lines),ymax=float(cross_lines), color='b', linestyle='-.')\n",
    "            axs[axe_x][1].fill_between([(x_ped[int(ep_env[t_init,2])-car_lane][id_ped]-t_init)*0.3,(x_ped[int(ep_env[t_init,2])-car_lane-1][id_ped]-t_init)*0.3],-20,20, color='b', alpha=0.05,label='pedestrian in lane')\n",
    "        #ax2.fill_between([(x_ped1-t_init)*0.3,(x_ped2-t_init)*0.3], min(ep_pos_car[t_init],ep_pos_ped[t_init]), min(max(ep_pos_car[min_t+t_init],ep_pos_ped[min_t+t_init]),30), color='r', alpha=0.1,label='pedestrian in crosswalk')\n",
    "    axs[axe_x][1].set_ylim(-20,20)\n",
    "    axs[axe_x][1].set_xlim(0,15)\n",
    "    cross_size=2.0*ep_env[t_init+1,0]/ep_env[t_init+1,2]\n",
    "    for i in range(2):#int(ep_env[t_init,2])+1):\n",
    "        axs[axe_x][1].axhline(y=-ep_cross[t_init+1] + (ep_car[t_init+1,axe_x,5]+i)*cross_size , color='r', linestyle='-.')\n",
    "    #ax2.axhline(y=0.0, color='b', linestyle='-.')\n",
    "    #ax2.axhline(y=10.0, color='b', linestyle='-.')\n",
    "    axs[axe_x][1].legend()\n",
    "    axs[axe_x][1].grid()\n",
    "    \n",
    "t+=1\n",
    "u+=1\n",
    "print(\"num_episode : \",num_episode)\n",
    "print(\"t : \",t)\n",
    "num_episode+=1\n",
    "fig.savefig('selfish_example.svg', format='svg')\n",
    "\n",
    "#print(t)\n",
    "#print(ep_reward_d[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "LDV = pd.read_csv('LDV.csv', sep=';',names=[\"sp\",\"acc\",\"step\",\"em_name\",\"em_val\"])\n",
    "LDV.pop('step')\n",
    "m = LDV == 0.0\n",
    "LDV['acc'] = LDV['acc'].replace(1.27676e-15,0.0)\n",
    "LDV['acc'] = LDV['acc'].astype(float)\n",
    "LDV_array = np.array(LDV.values)\n",
    "\n",
    "def info_co2(ep_car,ep_cross,LDV):\n",
    "    \"\"\"\n",
    "        Evaluate the CO2 emission per episode \n",
    "        :param states: state list\n",
    "        :param LDV: CO2 emission chart\n",
    "    \"\"\"\n",
    "    t=0\n",
    "    total_emission=[]\n",
    "    while t+1<len(ep_cross):\n",
    "        t_init=t\n",
    "        emission_val=[]\n",
    "        for car_i in range(env.nb_car):\n",
    "            while  t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                acc=math.trunc(((ep_car[t,car_i,0].item()//0.2)*0.2)*10.)/10.\n",
    "                speed=math.trunc(((ep_car[t,car_i,1].item()//0.5)*0.5)*10.)/10.\n",
    "                cond=(LDV.sp==speed)&(LDV.acc==acc)&(LDV.em_name==\"CO2\")\n",
    "                res=LDV[cond]['em_val'].item() *0.3\n",
    "                emission_val.append(res)\n",
    "                t+=1\n",
    "            total_emission.append(np.sum(np.array(emission_val),axis=0))\n",
    "        t+=1\n",
    "    torch_total_emission=np.array(total_emission)\n",
    "    total_emission_mean=np.mean(torch_total_emission)\n",
    "    total_emission_std=np.std(torch_total_emission)\n",
    "    print(\"\\nThe average CO2 emission is {:.2f}mg and its standard deviation is {:.2f} mg\".format(total_emission_mean.item(),total_emission_std.item()))\n",
    "    \n",
    "def get_average(ep_car,ep_ped,ep_cross):\n",
    "    ep_time=states[:,9]\n",
    "    #Info vitesse voiture\n",
    "    mean_speed=torch.mean(ep_car[:,0,1])\n",
    "    sqrt_speed=torch.std(ep_car[:,0,1])\n",
    "    print(\"La vitesse moyenne (voiture) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed.item(),sqrt_speed.item()))\n",
    "    #Info acclration voiture RMQ: trs peu reprsentatif...\n",
    "    mean_acc=torch.mean(torch.abs(ep_car[:,0,0]))\n",
    "    sqrt_acc=torch.std(ep_car[:,0,0])\n",
    "    print(\"\\nL'acclration moyenne (voiture) est de {:.2f} m/s2 et son cart-type est de {:.2f} m/s2\".format(mean_acc.item(),sqrt_acc.item()))\n",
    "    mean_speed_p=torch.mean(torch.abs(ep_ped[:,0,1]))\n",
    "    sqrt_speed_p=torch.std(torch.abs(ep_ped[:,0,1]))\n",
    "    print(\"\\nLa vitesse moyenne (piton) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed_p.item(),sqrt_speed_p.item()))    \n",
    "    #CO2 info\n",
    "    info_co2(ep_car,ep_cross,LDV) #CO2 info\n",
    "    #temps passage voiture\n",
    "    temp_cars=[]\n",
    "    all_temp_cars=[]\n",
    "    temp_peds=[]\n",
    "    decisions=[]\n",
    "    ped_direction=[]\n",
    "    waiting_times=[]\n",
    "    speed_cars=[]\n",
    "    all_decisions=[]\n",
    "    t=0\n",
    "    while t+1<len(ep_cross):\n",
    "        # respectivement: temps passage voiture / piton\n",
    "        t_init=t\n",
    "        t_end=t\n",
    "        #if(1 in ep_car[t_init+1,:,4]):\n",
    "        #temp_ped=np.array([0.]*env.nb_ped)\n",
    "        for ped_i in range(env.nb_ped):\n",
    "            waiting_time=0\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                if abs(ep_ped[t,ped_i,3])==ep_cross[t] and abs(ep_ped[t+1,ped_i,3])==ep_cross[t+1]:\n",
    "                    waiting_time+=0.3\n",
    "                if(ep_ped[t,ped_i,3]*ep_ped[t,ped_i,8]<ep_cross[t] and ep_ped[t+1,ped_i,3]*ep_ped[t+1,ped_i,8]>=ep_cross[t+1]):\n",
    "                    temp_peds.append((t-t_init)*0.3)\n",
    "                t+=1\n",
    "            waiting_times.append(waiting_time)\n",
    "            ped_direction.append(int(-ep_ped[t_init,ped_i,8]/2. +0.5))\n",
    "            t_end=max(t_end,t)\n",
    "        #temp_peds.append(temp_ped)\n",
    "        #temp_car=np.array([0.]*env.nb_car)\n",
    "        for car_i in range(env.nb_car):\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                decision=ep_car[t,car_i,4]\n",
    "                if(ep_car[t_init+1,car_i,4]==1):\n",
    "                    speed_cars.append(ep_car[t,car_i,1])\n",
    "                if(-25.+ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and -25.+ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "                    all_temp_cars.append((t-t_init)*0.3)\n",
    "                if(-25.+ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and -25.+ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0)and (ep_car[t_init+1,car_i,4]==1):\n",
    "                    temp_cars.append((t-t_init)*0.3)\n",
    "                    #speed_cars.append(ep_car[t,car_i,1])\n",
    "                t+=1\n",
    "            decisions.append(decision)\n",
    "            t_end=max(t_end,t)\n",
    "        #temp_cars.append(temp_car)\n",
    "            #temps.append([(t-t_init)*0.3,temps_i[0],temps_i[1]])\n",
    "        t=t_end+1\n",
    "    #total_temps=torch.tensor([temps]).reshape((-1,3))\n",
    "    mean_speed_cars=torch.mean(torch.tensor(speed_cars).flatten())\n",
    "    sqrt_speed_cars=torch.std(torch.tensor(speed_cars).flatten())\n",
    "    mean_temp_cars=torch.mean(torch.tensor(temp_cars).flatten())\n",
    "    mean_all_temp_cars=torch.mean(torch.tensor(all_temp_cars).flatten())\n",
    "    mean_temp_peds=torch.mean(torch.tensor(temp_peds).flatten())\n",
    "    decisions_tensor=torch.tensor(decisions).reshape(-1,env.nb_car)\n",
    "    scenario=torch.sum(decisions_tensor, axis=1)\n",
    "    print(\"La vitesse moyenne (voiture 1) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed_cars.item(),sqrt_speed_cars.item()))\n",
    "\n",
    "    print(\"\\nLes temps moyens:\")\n",
    "    print(\"voiture 1 a 25 metres: {:.2f} s\".format(mean_temp_cars))\n",
    "    print(\"voiture 1 a 25 metres std: \", torch.std(torch.tensor(temp_cars)))\n",
    "    print(\"voiture all a 25 metres: {:.2f} s\".format(mean_all_temp_cars))\n",
    "    print(\"voiture all a 25 metres std: \", torch.std(torch.tensor(all_temp_cars)))\n",
    "    print(\"piton: {:.2f} s\".format(mean_temp_peds))\n",
    "    print(\"piton std: \", torch.std(torch.tensor(temp_peds)))\n",
    "    print(\"Yield decision: \", sum([1 for dec in np.array(decisions) if dec ==1])/len(decisions))\n",
    "    print(\"Go first decision: \", sum([1 for dec in np.array(decisions) if dec ==-1])/len(decisions))\n",
    "    print(\"Le temps moyen d'attente du pieton: \", np.mean(waiting_times))\n",
    "    print(\"Le temps std d'attente du pieton: \", np.std(waiting_times))\n",
    "    if(env.nb_car==2):\n",
    "        size_scenario=len(decisions_tensor)\n",
    "        print(\"Scenario 11: \", sum([1 for i in range(size_scenario) if sum(decisions_tensor[i]) ==2])/len(scenario))\n",
    "        print(\"Scenario -1-1: \", sum([1 for i in range(size_scenario) if sum(decisions_tensor[i]) ==-2])/len(scenario))\n",
    "        print(\"Scenario -1 1: \", sum([1 for i in range(size_scenario) if decisions_tensor[i][ped_direction[i]] ==-1 and decisions_tensor[i][1-ped_direction[i]]==1])/len(scenario))\n",
    "        print(\"Scenario 1 -1: \", sum([1 for i in range(size_scenario) if decisions_tensor[i][ped_direction[i]] ==1 and decisions_tensor[i][1-ped_direction[i]]==-1])/len(scenario))\n",
    "    #print(torch.std(total_temps,dim=0))\n",
    "get_average(ep_car,ep_ped,ep_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9408b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        decisions_pos.append(decision)\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,2)\n",
    "#plt.plot(initial_pos,decisions_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b66225",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data=decisions_pos[decisions_pos[:, 0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data_cumul_yield=[]\n",
    "sort_data_cumul_go=[]\n",
    "distances=[]\n",
    "cumul_yield=0\n",
    "cumul_go=0\n",
    "nbr_yield=sum([1 for dec in sort_data[:,1] if dec ==1])\n",
    "nbr_go=sum([1 for dec in sort_data[:,1] if dec ==-1])\n",
    "for i in range(int(len(sort_data)/10)):\n",
    "    distances.append(sum([sort_data[i*10 +j,0] for j in range(10)])/10.)\n",
    "    cumul_yield=sum([(sort_data[i*10 +j,1]==1) for j in range(10)])\n",
    "    cumul_go=sum([(sort_data[i*10 +j,1]==-1) for j in range(10)])\n",
    "    sort_data_cumul_yield.append(cumul_yield/(cumul_yield+cumul_go))\n",
    "    sort_data_cumul_go.append(cumul_go/(cumul_yield+cumul_go))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f93a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.flip(distances),np.flip(np.array(sort_data_cumul_yield)),label=\"Yield\")\n",
    "plt.plot(np.flip(distances),np.flip(np.array(sort_data_cumul_go)),label=\"Go first\")\n",
    "plt.title(\"Percentage \")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4af8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([sort_data[i,0] for i in range(len(sort_data)) if sort_data[i,1]>0],bins=50)\n",
    "plt.hist([sort_data[i,0] for i in range(len(sort_data)) if sort_data[i,1]<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_ped[t,0,3]*ep_ped[t,0,8]<ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>=ep_cross[t+1]):\n",
    "                decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                print(ep_car[t,car_i,3])\n",
    "                decisions_pos.append(ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        decisions_pos.append(decision)\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                #decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                decisions_pos.append(ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        decisions_pos.append(decision)\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial Position of the car\")\n",
    "plt.ylabel(\"Car speed in the crosswalk  of the car\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f14c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        decisions_pos.append(abs(ep_ped[t,0,3])-ep_env[t,0])#ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "        decisions_pos.append(ep_car[t+1,car_i,3])\n",
    "        ped_when_vehicle_go=10\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "            #if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                #decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                ped_when_vehicle_go=ep_ped[t,0,3]*ep_ped[t,0,8]#ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        #decisions_pos.append(ped_when_vehicle_go)\n",
    "        decisions_pos.append(decision)\n",
    "        t+=1\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial pedestrian-crosswalk distance\")\n",
    "plt.ylabel(\"Initial car-crosswalk distance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        if(sum(ep_car[t_init+1,:,4])==2):\n",
    "            decisions_pos.append(abs(ep_ped[t,0,3])-ep_env[t,0])#ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "            decisions_pos.append(ep_car[t+1,car_i,3])\n",
    "        ped_when_vehicle_go=10\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "            #if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                #decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                ped_when_vehicle_go=ep_ped[t,0,3]*ep_ped[t,0,8]#ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        #decisions_pos.append(ped_when_vehicle_go)\n",
    "        if(sum(ep_car[t_init+1,:,4])==2):\n",
    "            decisions_pos.append(decision)\n",
    "        t+=1\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial pedestrian-crosswalk distance\")\n",
    "plt.ylabel(\"Initial car-crosswalk distance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        if(sum(ep_car[t_init+1,:,4])==-2):\n",
    "            decisions_pos.append(abs(ep_ped[t,0,3])-ep_env[t,0])#ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "            decisions_pos.append(ep_car[t+1,car_i,3])\n",
    "        ped_when_vehicle_go=10\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "            #if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                #decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                ped_when_vehicle_go=ep_ped[t,0,3]*ep_ped[t,0,8]#ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        #decisions_pos.append(ped_when_vehicle_go)\n",
    "        if(sum(ep_car[t_init+1,:,4])==-2):\n",
    "            decisions_pos.append(decision)\n",
    "        t+=1\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial pedestrian-crosswalk distance\")\n",
    "plt.ylabel(\"Initial car-crosswalk distance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    ped_direction=int(-ep_ped[t_init,0,8]/2. +0.5)\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        if(ep_car[t_init+1,ped_direction,4]==1 and ep_car[t_init+1,1-ped_direction,4]==-1):\n",
    "            decisions_pos.append(abs(ep_ped[t,0,3])-ep_env[t,0])#ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "            decisions_pos.append(ep_car[t+1,car_i,3])\n",
    "        ped_when_vehicle_go=10\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "            #if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                #decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                ped_when_vehicle_go=ep_ped[t,0,3]*ep_ped[t,0,8]#ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        #decisions_pos.append(ped_when_vehicle_go)\n",
    "        if(ep_car[t_init+1,ped_direction,4]==1 and ep_car[t_init+1,1-ped_direction,4]==-1):\n",
    "            decisions_pos.append(decision)\n",
    "        t+=1\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial pedestrian-crosswalk distance\")\n",
    "plt.ylabel(\"Initial car-crosswalk distance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    ped_direction=int(-ep_ped[t_init,0,8]/2. +0.5)\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        if(ep_car[t_init+1,ped_direction,4]==-1 and ep_car[t_init+1,1-ped_direction,4]==1):\n",
    "            decisions_pos.append(abs(ep_ped[t,0,3])-ep_env[t,0])#ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "            decisions_pos.append(ep_car[t+1,car_i,3])\n",
    "        ped_when_vehicle_go=10\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "            #if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                #decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                ped_when_vehicle_go=ep_ped[t,0,3]*ep_ped[t,0,8]#ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        #decisions_pos.append(ped_when_vehicle_go)\n",
    "        if(ep_car[t_init+1,ped_direction,4]==-1 and ep_car[t_init+1,1-ped_direction,4]==1):\n",
    "            decisions_pos.append(decision)\n",
    "        t+=1\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial pedestrian-crosswalk distance\")\n",
    "plt.ylabel(\"Initial car-crosswalk distance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color(i):\n",
    "    if(i==1):\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"red\"\n",
    "decisions_pos=[]\n",
    "t_init=0\n",
    "t=0\n",
    "while t+1<len(ep_cross):\n",
    "    for car_i in range(env.nb_car):\n",
    "        t=t_init\n",
    "        decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "        while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "            if(ep_ped[t,0,3]*ep_ped[t,0,8]<=-ep_cross[t] and ep_ped[t+1,0,3]*ep_ped[t+1,0,8]>-ep_cross[t+1]):\n",
    "                decisions_pos.append(ep_car[t,car_i,3]-ep_ped[t,0,2])\n",
    "                #decisions_pos.append(ep_car[t,car_i,1])\n",
    "            decision=ep_car[t,car_i,4]\n",
    "            t+=1\n",
    "        decisions_pos.append(decision)\n",
    "    t_init=t+1\n",
    "#decisions_tensor=np.expand_dims(np.array(decisions), axis=0)\n",
    "#initial_pos_tensor=np.expand_dims(np.array(initial_pos), axis=0)\n",
    "decisions_pos=np.array(decisions_pos).reshape(-1,3)\n",
    "colors=[change_color(decisions_pos[i,2]) for i in range(len(decisions_pos))]\n",
    "#plt.plot(initial_pos,decisions_tensor)\n",
    "plt.scatter(decisions_pos[:,0], decisions_pos[:,1], c=colors, alpha=0.5)\n",
    "plt.xlabel(\"Initial Position of the car\")\n",
    "plt.ylabel(\"Car Position when pedestrian start crossing\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b77b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0de0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# create some randomly ddistributed data:\n",
    "data = np.random.randn(10000)\n",
    "\n",
    "# sort the data:\n",
    "data_sorted = np.sort(data)\n",
    "\n",
    "# calculate the proportional values of samples\n",
    "p = 1. * np.arange(len(data)) / (len(data) - 1)\n",
    "\n",
    "# plot the sorted data:\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(p, data_sorted)\n",
    "ax1.set_xlabel('$p$')\n",
    "ax1.set_ylabel('$x$')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(data_sorted, p)\n",
    "ax2.set_xlabel('$x$')\n",
    "ax2.set_ylabel('$p$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "LDV = pd.read_csv('LDV.csv', sep=';',names=[\"sp\",\"acc\",\"step\",\"em_name\",\"em_val\"])\n",
    "LDV.pop('step')\n",
    "m = LDV == 0.0\n",
    "LDV['acc'] = LDV['acc'].replace(1.27676e-15,0.0)\n",
    "LDV['acc'] = LDV['acc'].astype(float)\n",
    "LDV_array = np.array(LDV.values)\n",
    "\n",
    "def info_co2(ep_car,ep_cross,LDV):\n",
    "    \"\"\"\n",
    "        Evaluate the CO2 emission per episode \n",
    "        :param states: state list\n",
    "        :param LDV: CO2 emission chart\n",
    "    \"\"\"\n",
    "    t=0\n",
    "    total_emission=[]\n",
    "    while t+1<len(ep_cross):\n",
    "        t_init=t\n",
    "        emission_val=[]\n",
    "        for car_i in range(env.nb_car):\n",
    "            while  t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                acc=math.trunc(((ep_car[t,car_i,0].item()//0.2)*0.2)*10.)/10.\n",
    "                speed=math.trunc(((ep_car[t,car_i,1].item()//0.5)*0.5)*10.)/10.\n",
    "                cond=(LDV.sp==speed)&(LDV.acc==acc)&(LDV.em_name==\"CO2\")\n",
    "                res=LDV[cond]['em_val'].item() *0.3\n",
    "                emission_val.append(res)\n",
    "                t+=1\n",
    "            total_emission.append(np.sum(np.array(emission_val),axis=0))\n",
    "        t+=1\n",
    "    torch_total_emission=np.array(total_emission)\n",
    "    total_emission_mean=np.mean(torch_total_emission)\n",
    "    total_emission_std=np.std(torch_total_emission)\n",
    "    print(\"\\nThe average CO2 emission is {:.2f}mg and its standard deviation is {:.2f} mg\".format(total_emission_mean.item(),total_emission_std.item()))\n",
    "    \n",
    "def get_average(ep_car,ep_ped,ep_cross):\n",
    "    ep_time=states[:,9]\n",
    "    #Info vitesse voiture\n",
    "    mean_speed=torch.mean(ep_car[:,0,1])\n",
    "    sqrt_speed=torch.std(ep_car[:,0,1])\n",
    "    print(\"La vitesse moyenne (voiture) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed.item(),sqrt_speed.item()))\n",
    "    #Info acclration voiture RMQ: trs peu reprsentatif...\n",
    "    mean_acc=torch.mean(torch.abs(ep_car[:,0,0]))\n",
    "    sqrt_acc=torch.std(ep_car[:,0,0])\n",
    "    print(\"\\nL'acclration moyenne (voiture) est de {:.2f} m/s2 et son cart-type est de {:.2f} m/s2\".format(mean_acc.item(),sqrt_acc.item()))\n",
    "    mean_speed_p=torch.mean(torch.abs(ep_ped[:,0,1]))\n",
    "    sqrt_speed_p=torch.std(torch.abs(ep_ped[:,0,1]))\n",
    "    print(\"\\nLa vitesse moyenne (piton) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed_p.item(),sqrt_speed_p.item()))    \n",
    "    #CO2 info\n",
    "    info_co2(ep_car,ep_cross,LDV) #CO2 info\n",
    "    #temps passage voiture\n",
    "    temp_cars=[]\n",
    "    all_temp_cars=[]\n",
    "    temp_peds=[]\n",
    "    decisions=[]\n",
    "    speed_cars=[]\n",
    "    all_decisions=[]\n",
    "    waiting_times=[]\n",
    "    t=0\n",
    "    while t+1<len(ep_cross):\n",
    "        # respectivement: temps passage voiture / piton\n",
    "        t_init=t\n",
    "        t_end=t\n",
    "        #if(1 in ep_car[t_init+1,:,4]):\n",
    "        \n",
    "        #temp_ped=np.array([0.]*env.nb_ped)\n",
    "        for ped_i in range(env.nb_ped):\n",
    "            waiting_time=0\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                if(ep_ped[t,ped_i,3])==ep_cross[t]:\n",
    "                    waiting_time+=0.3\n",
    "                if(ep_ped[t,ped_i,3]*ep_ped[t,ped_i,8]<ep_cross[t] and ep_ped[t+1,ped_i,3]*ep_ped[t+1,ped_i,8]>=ep_cross[t+1]):\n",
    "                    temp_peds.append((t-t_init)*0.3)\n",
    "                t+=1\n",
    "            waiting_times.append(waiting_time)\n",
    "            t_end=max(t_end,t)\n",
    "       # temp_peds.append(temp_ped)\n",
    "        #temp_car=np.array([0.]*env.nb_car)\n",
    "        for car_i in range(env.nb_car):\n",
    "            t=t_init\n",
    "            #if(1 in ep_car[t_init+1,:,4]):\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                decision=ep_car[t,car_i,4]\n",
    "                if(ep_car[t_init+1,car_i,4]==1):\n",
    "                    speed_cars.append(ep_car[t,car_i,1])\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0):\n",
    "                    all_temp_cars.append((t-t_init)*0.3)\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])>=0.0) and (ep_car[t_init+1,car_i,4]==1):\n",
    "                    temp_cars.append((t-t_init)*0.3)\n",
    "                t+=1\n",
    "            if(ep_car[t_init+1,car_i,4]==1):\n",
    "                decisions.append(decision)\n",
    "            all_decisions.append(decision)\n",
    "            t_end=max(t_end,t)\n",
    "        #temp_cars.append(temp_car)\n",
    "            #temps.append([(t-t_init)*0.3,temps_i[0],temps_i[1]])\n",
    "        t=t_end+1\n",
    "    #total_temps=torch.tensor([temps]).reshape((-1,3))\n",
    "    mean_speed_cars=torch.mean(torch.tensor(speed_cars).flatten())\n",
    "    sqrt_speed_cars=torch.std(torch.tensor(speed_cars).flatten())\n",
    "    mean_temp_cars=torch.mean(torch.tensor(temp_cars).flatten())\n",
    "    mean_all_temp_cars=np.mean(np.array(all_temp_cars).flatten())\n",
    "    mean_temp_peds=torch.mean(torch.tensor(temp_peds).flatten())\n",
    "    #decisions_tensor=torch.tensor(decisions).flatten()#.reshape(-1,env.nb_car)\n",
    "    all_decisions_tensor=torch.tensor(all_decisions).reshape(-1,env.nb_car)\n",
    "    #print(all_decisions_tensor)\n",
    "    #scenario=torch.sum(decisions_tensor, axis=1)\n",
    "    all_scenario=torch.sum(all_decisions_tensor, axis=1)\n",
    "    print(\"La vitesse moyenne (voiture 1) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed_cars.item(),sqrt_speed_cars.item()))\n",
    "    print(\"\\nLes temps moyens:\")\n",
    "    print(\"voiture 1: {:.2f} s\".format(mean_temp_cars))\n",
    "    print(\"voiture 1 std: \", torch.std(torch.tensor(temp_cars)))\n",
    "    print(\"voiture all: {:.2f} s\".format(mean_all_temp_cars))\n",
    "    print(\"voiture all std: \", np.std(np.array(all_temp_cars)))\n",
    "    print(\"piton: {:.2f} s\".format(mean_temp_peds))\n",
    "    print(\"piton std: \", torch.std(torch.tensor(temp_peds)))\n",
    "    print(\"Yield decision: \", sum([1 for dec in np.array(all_decisions) if dec ==1])/len(all_decisions))\n",
    "    print(\"Go first decision: \", sum([1 for dec in np.array(all_decisions) if dec ==-1])/len(all_decisions))\n",
    "    print(\"Le temps moyen d'attente du pieton: \", np.mean(waiting_times))\n",
    "    print(\"Le temps std d'attente du pieton: \", np.std(waiting_times))\n",
    "    print(\"Scenario 1 1: \", sum([1 for sce in (all_decisions_tensor) if sum(sce) ==2])/len(all_scenario))\n",
    "    print(\"Scenario -1 -1: \", sum([1 for sce in (all_decisions_tensor) if sum(sce) ==-2])/len(all_scenario))\n",
    "    print(\"Scenario -1 1: \", sum([1 for sce in (all_decisions_tensor) if sce[0] ==-1 and sce[1]==1])/len(all_scenario))\n",
    "    print(\"Scenario 1 -1: \", sum([1 for sce in (all_decisions_tensor) if sce[0] ==1 and sce[1]==-1])/len(all_scenario))\n",
    "    #print(torch.std(total_temps,dim=0))\n",
    "get_average(ep_car,ep_ped,ep_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2166e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.pedestrian[0].waiting_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91542fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "ep_time=[i*0.3 for i in range(t-t_init+1)]\n",
    "fig, ( ax4, ax5, ax6, ax7) = plt.subplots(1, 4,figsize=(20, 8))\n",
    "\n",
    "ax4.set_title('Delta')\n",
    "ax4.set_xlabel(\"Time (s)\")\n",
    "ax4.set_ylabel(\"\")\n",
    "for id_ped in range(env.nb_ped):\n",
    "    ax4.plot(ep_time, ep_ped[t_init:t+1,id_ped,4],label='pedestrian'+str(id_ped))\n",
    "ax4.legend()\n",
    "    \n",
    "    \n",
    "ax5.set_title('Pedestrian position axe X')\n",
    "ax5.set_xlabel(\"Time (s)\")\n",
    "ax5.set_ylabel(\"Speed (m/s)\")\n",
    "for id_ped in range(env.nb_ped):\n",
    "    ax5.plot(ep_time, ep_ped[t_init:t+1,id_ped,1],label='pedestrian'+str(id_ped))\n",
    "ax5.legend()\n",
    "ax5.set_xlim(0,15)\n",
    "#ax5.set_title('DL')\n",
    "#ax5.set_xlabel(\"Time (s)\")\n",
    "#ax5.set_ylabel(\"Value \")\n",
    "#ax5.plot(ep_time, states[t_init:t+1,5 ])#ep_reward[t_init:t+1])#ep_reward[t_init:t+1],color='r')\n",
    "#ax5.axhline(y=0, color='r', linestyle='-.')\n",
    "\n",
    "ax6.set_title('Reward')\n",
    "ax6.set_xlabel(\"Time (s)\")\n",
    "ax6.set_ylabel(\"Value\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax6.plot(ep_time,ep_reward_c[t_init:t+1][:,id_car],label='car'+str(id_car))#ep_reward[t_init:t+1])#ep_reward[t_init:t+1],color='r')\n",
    "ax6.legend()\n",
    "#print(ep_reward_d)\n",
    "ax7.set_title('Light')\n",
    "ax7.set_xlabel(\"Time (s)\")\n",
    "ax7.set_ylabel(\"Light\")\n",
    "for id_car in range(env.nb_car):\n",
    "    ax7.plot(ep_time,ep_car[t_init:t+1,id_car,4],label='car'+str(id_car))#,color='black')#ep_reward[t_init:t+1])#ep_reward[t_init:t+1],color='r')\n",
    "    #ax7.scatter(ep_time,ep_car[t_init:t+1,id_car,4],c=ep_car[t_init:t+1,id_car,4],cmap='RdYlGn')\n",
    "    ax7\n",
    "    ax7.legend()\n",
    "#print(ep_reward_d)\n",
    "t+=1\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    " \n",
    "def save_object(obj):\n",
    "    try:\n",
    "        with open(\"test_data_acc6.pickle\", \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as ex:\n",
    "        print(\"Error during pickling object (Possibly unsupported):\", ex)\n",
    "dataset=[]\n",
    "for i in range(1000):\n",
    "    env.reset()\n",
    "    dataset.append(copy.deepcopy(env))\n",
    "save_object(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68414641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "LDV = pd.read_csv('LDV.csv', sep=';',names=[\"sp\",\"acc\",\"step\",\"em_name\",\"em_val\"])\n",
    "LDV.pop('step')\n",
    "m = LDV == 0.0\n",
    "LDV['acc'] = LDV['acc'].replace(1.27676e-15,0.0)\n",
    "LDV['acc'] = LDV['acc'].astype(float)\n",
    "LDV_array = np.array(LDV.values)\n",
    "\n",
    "def info_co2(ep_car,ep_cross,LDV):\n",
    "    \"\"\"\n",
    "        Evaluate the CO2 emission per episode \n",
    "        :param states: state list\n",
    "        :param LDV: CO2 emission chart\n",
    "    \"\"\"\n",
    "    t=0\n",
    "    total_emission=[]\n",
    "    while t+1<len(ep_cross):\n",
    "        t_init=t\n",
    "        emission_val=[]\n",
    "        for car_i in range(env.nb_car):\n",
    "            while  t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                acc=math.trunc(((ep_car[t,car_i,0].item()//0.2)*0.2)*10.)/10.\n",
    "                speed=math.trunc(((ep_car[t,car_i,1].item()//0.5)*0.5)*10.)/10.\n",
    "                cond=(LDV.sp==speed)&(LDV.acc==acc)&(LDV.em_name==\"CO2\")\n",
    "                res=LDV[cond]['em_val'].item() *0.3\n",
    "                emission_val.append(res)\n",
    "                t+=1\n",
    "            total_emission.append(np.sum(np.array(emission_val),axis=0))\n",
    "        t+=1\n",
    "    torch_total_emission=np.array(total_emission)\n",
    "    total_emission_mean=np.mean(torch_total_emission)\n",
    "    total_emission_std=np.std(torch_total_emission)\n",
    "    print(\"\\nThe average CO2 emission is {:.2f}mg and its standard deviation is {:.2f} mg\".format(total_emission_mean.item(),total_emission_std.item()))\n",
    "    \n",
    "def get_average(ep_car,ep_ped,ep_cross):\n",
    "    ep_time=states[:,9]\n",
    "    #Info vitesse voiture\n",
    "    mean_speed=torch.mean(ep_car[:,0,1])\n",
    "    sqrt_speed=torch.std(ep_car[:,0,1])\n",
    "    print(\"La vitesse moyenne (voiture) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed.item(),sqrt_speed.item()))\n",
    "    #Info acclration voiture RMQ: trs peu reprsentatif...\n",
    "    mean_acc=torch.mean(torch.abs(ep_car[:,0,0]))\n",
    "    sqrt_acc=torch.std(ep_car[:,0,0])\n",
    "    print(\"\\nL'acclration moyenne (voiture) est de {:.2f} m/s2 et son cart-type est de {:.2f} m/s2\".format(mean_acc.item(),sqrt_acc.item()))\n",
    "    mean_speed_p=torch.mean(torch.abs(ep_ped[:,0,1]))\n",
    "    sqrt_speed_p=torch.std(torch.abs(ep_ped[:,0,1]))\n",
    "    print(\"\\nLa vitesse moyenne (piton) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed_p.item(),sqrt_speed_p.item()))    \n",
    "    #CO2 info\n",
    "    info_co2(ep_car,ep_cross,LDV) #CO2 info\n",
    "    #temps passage voiture\n",
    "    temp_cars=[]\n",
    "    all_temp_cars=[]\n",
    "    temp_peds=[]\n",
    "    finish_cross_interact=[]\n",
    "    finish_cross_nointeract=[]\n",
    "    decisions=[]\n",
    "    ped_direction=[]\n",
    "    waiting_times=[]\n",
    "    speed_cars=[]\n",
    "    all_decisions=[]\n",
    "    t=0\n",
    "    while t+1<len(ep_cross):\n",
    "        # respectivement: temps passage voiture / piton\n",
    "        t_init=t\n",
    "        t_end=t\n",
    "        #temp_ped=np.array([0.]*env.nb_ped)\n",
    "        for ped_i in range(env.nb_ped):\n",
    "            waiting_time=0\n",
    "            ped_leave=0\n",
    "            t=t_init\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                if abs(ep_ped[t,ped_i,3])==ep_cross[t] and abs(ep_ped[t+1,ped_i,3])==ep_cross[t+1]:\n",
    "                #if(ep_ped[t,ped_i,1]==0.):\n",
    "                    waiting_time+=0.3\n",
    "                if abs(ep_ped[t,ped_i,3])==0 and abs(ep_ped[t+1,ped_i,3])==0:\n",
    "                #if(ep_ped[t,ped_i,1]==0.):\n",
    "                    waiting_time+=0.3\n",
    "                if(ep_ped[t,ped_i,3]*ep_ped[t,ped_i,8]<ep_cross[t] and ep_ped[t+1,ped_i,3]*ep_ped[t+1,ped_i,8]>=ep_cross[t+1]):\n",
    "                    ped_leave=(t-t_init)*0.3\n",
    "                t+=1\n",
    "            if(ped_leave==0):\n",
    "                ped_leave=(t-t_init)*0.3\n",
    "            temp_peds.append(ped_leave)\n",
    "            finish_cross_interact.append(ped_leave)\n",
    "            finish_cross_nointeract.append(ped_leave-waiting_time)\n",
    "            waiting_times.append(waiting_time)\n",
    "            ped_direction.append(int(-ep_ped[t_init,ped_i,8]/2. +0.5))\n",
    "            t_end=max(t_end,t)\n",
    "       # temp_peds.append(temp_ped)\n",
    "        #temp_car=np.array([0.]*env.nb_car)\n",
    "        for car_i in range(env.nb_car):\n",
    "            t=t_init\n",
    "            car_leave=0\n",
    "            finish_cross_nointeract.append((25.-ep_car[t_init,car_i,3])/ep_car[t_init,car_i,1])\n",
    "            while t+1<len(ep_cross) and ep_cross[t]==ep_cross[t+1]:\n",
    "                decision=ep_car[t,car_i,4]\n",
    "                if(ep_car[t_init+1,car_i,4]==1):\n",
    "                    speed_cars.append(ep_car[t,car_i,1])\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])-25<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])-25>=0.0):\n",
    "                    car_leave=(t-t_init)*0.3\n",
    "                if(ep_car[t,car_i,3]-max(ep_ped[t+1,:,2])-25<0.0 and ep_car[t+1,car_i,3]-max(ep_ped[t+1,:,2])-25>=0.0)and (ep_car[t_init+1,car_i,4]==1):\n",
    "                    temp_cars.append((t-t_init)*0.3)\n",
    "                    #speed_cars.append(ep_car[t,car_i,1])\n",
    "                t+=1\n",
    "            if(ep_car[t_init+1,car_i,4]==1):\n",
    "                decisions.append(decision)\n",
    "            if(car_leave==0):\n",
    "                car_leave=(t-t_init)*0.3\n",
    "            all_decisions.append(decision)\n",
    "            all_temp_cars.append(car_leave)\n",
    "            finish_cross_interact.append(car_leave)\n",
    "            t_end=max(t_end,t)\n",
    "        #temp_cars.append(temp_car)\n",
    "            #temps.append([(t-t_init)*0.3,temps_i[0],temps_i[1]])\n",
    "        t=t_end+1\n",
    "    #total_temps=torch.tensor([temps]).reshape((-1,3))\n",
    "    mean_speed_cars=torch.mean(torch.tensor(speed_cars).flatten())\n",
    "    sqrt_speed_cars=torch.std(torch.tensor(speed_cars).flatten())\n",
    "    mean_temp_cars=torch.mean(torch.tensor(temp_cars).flatten())\n",
    "    mean_all_temp_cars=torch.mean(torch.tensor(all_temp_cars).flatten())\n",
    "    mean_temp_peds=torch.mean(torch.tensor(temp_peds).flatten())\n",
    "    #decisions_tensor=torch.tensor(decisions).reshape(-1,env.nb_car)\n",
    "    all_decisions_tensor=torch.tensor(all_decisions).reshape(-1,env.nb_car)\n",
    "    all_scenario=torch.sum(all_decisions_tensor, axis=1)\n",
    "    #scenario=torch.sum(decisions_tensor, axis=1)\n",
    "    max_finish_cross_interact=torch.max(torch.tensor(finish_cross_interact).reshape(-1,env.nb_car+env.nb_ped),dim=1, keepdim=True).values\n",
    "    #print(max_finish_cross_interact)\n",
    "    max_finish_cross_nointeract=torch.max(torch.tensor(finish_cross_nointeract).reshape(-1,env.nb_car+env.nb_ped),dim=1, keepdim=True).values\n",
    "    interaction_cost=max_finish_cross_interact-max_finish_cross_nointeract\n",
    "    max_finish_compare=torch.tensor(finish_cross_interact).reshape(-1,env.nb_car+env.nb_ped)-torch.tensor(finish_cross_nointeract).reshape(-1,env.nb_car+env.nb_ped)#,dim=1)\n",
    "\n",
    "    print(\"La vitesse moyenne (voiture 1) est de {:.2f} m/s et son cart-type est de {:.2f} m/s\".format(mean_speed_cars.item(),sqrt_speed_cars.item()))\n",
    "    print(\"Le cout de l'interaction est de :\",torch.mean(interaction_cost))\n",
    "    print(\"Le cout max de l'interaction est de :\",torch.mean(max_finish_compare))\n",
    "\n",
    "    print(\"\\nLes temps moyens:\")\n",
    "    print(\"voiture 1 a 25 metres: {:.2f} s\".format(mean_temp_cars))\n",
    "    print(\"voiture 1 a 25 metres std: \", torch.std(torch.tensor(temp_cars)))\n",
    "    print(\"voiture a 25 metres all: {:.2f} s\".format(mean_all_temp_cars))\n",
    "    print(\"voiture a 25 metres all std: \", torch.std(torch.tensor(all_temp_cars)))\n",
    "    print(\"piton: {:.2f} s\".format(mean_temp_peds))\n",
    "    print(\"piton std: \", torch.std(torch.tensor(temp_peds)))\n",
    "    print(\"Yield decision: \", sum([1 for dec in np.array(all_decisions) if dec ==1])/len(all_scenario))\n",
    "    print(\"Go first decision: \", sum([1 for dec in np.array(all_decisions) if dec ==-1])/len(all_scenario))\n",
    "    print(\"Le temps moyen d'attente du pieton: \", np.mean(waiting_times))\n",
    "    print(\"Le temps std d'attente du pieton: \", np.std(waiting_times))\n",
    "    if(env.nb_car==2):\n",
    "        print(\"Scenario 1 1: \", sum([1 for sce in (all_decisions_tensor) if sum(sce) ==2])/len(all_scenario))\n",
    "        print(\"Scenario -1 -1: \", sum([1 for sce in (all_decisions_tensor) if sum(sce) ==-2])/len(all_scenario))\n",
    "        print(\"Scenario -1 1: \", sum([1 for sce in (all_decisions_tensor) if sce[0] ==-1 and sce[1]==1])/len(all_scenario))\n",
    "        print(\"Scenario 1 -1: \", sum([1 for sce in (all_decisions_tensor) if sce[0] ==1 and sce[1]==-1])/len(all_scenario))\n",
    "    #print(torch.std(total_temps,dim=0))\n",
    "get_average(ep_car,ep_ped,ep_cross)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
